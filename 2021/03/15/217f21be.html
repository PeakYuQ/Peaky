<!DOCTYPE html><html lang="zh-Hans"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="There is no description"><title> | NoteBook</title><link rel="stylesheet" type="text/css" href="/peaky/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="/peaky/css/dark.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/peaky/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/peaky/favicon.ico"><link rel="apple-touch-icon" href="/peaky/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/peaky/apple-touch-icon.png"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><div class="darkmode-toggle">ğŸŒ“</div><script>var prefersDarkMode = window.matchMedia('(prefers-color-scheme: dark)');
var toggle = document.querySelector('.darkmode-toggle');
var html = document.querySelector('html');

html.dataset.dark = localStorage.dark || prefersDarkMode.matches;

toggle.addEventListener('click', () => {
localStorage.dark = !(html.dataset.dark == 'true');
html.dataset.dark = localStorage.dark;
});</script><meta name="generator" content="Hexo 6.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">NoteBook</h1><a id="logo" href="/peaky/.">NoteBook</a><p class="description">Always believe that something wonderful is about to hanppen!</p></div><div id="nav-menu"><a class="current" href="/peaky/."><i class="fa fa-home"> é¦–é¡µ</i></a><a href="/peaky/archives/"><i class="fa fa-archive"> å½’æ¡£</i></a><a href="/peaky/atom.xml"><i class="fa fa-rss"> è®¢é˜…</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title"></h1><div class="post-meta">2021-03-15<span> | </span><span class="category"><a href="/peaky/categories/RL/">RL</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 10.3k</span><span class="post-meta-item-text"> Words</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 46</span><span class="post-meta-item-text"> Minutes</span></span></span></div><a class="disqus-comment-count" href="/peaky/2021/03/15/217f21be.html#vcomment"><span class="valine-comment-count" data-xid="/peaky/2021/03/15/217f21be.html"></span><span> Comment</span></a><div class="post-content"><h4 id="å¼ºåŒ–å­¦ä¹ ä»‹ç»"><a href="#å¼ºåŒ–å­¦ä¹ ä»‹ç»" class="headerlink" title="å¼ºåŒ–å­¦ä¹ ä»‹ç»"></a>å¼ºåŒ–å­¦ä¹ ä»‹ç»</h4><p>æ ¹æ®ä¸åŒçš„åˆ†åˆ—æ–¹æ³•å¯ä»¥å°†å¼ºåŒ–å­¦ä¹ ç®—æ³•åˆ†æˆä¸åŒçš„ç§ç±»ï¼š<br><strong>1.åŸºäºæ¦‚ç‡ï¼ˆpolicy-basedï¼‰å’ŒåŸºäºä»·å€¼ï¼ˆvalue-basedï¼‰</strong></p>
<p>åŸºäºæ¦‚ç‡æ˜¯å¼ºåŒ–å­¦ä¹ ä¸­æœ€ç›´æ¥çš„ä¸€ç§, ä»–èƒ½é€šè¿‡æ„Ÿå®˜åˆ†ææ‰€å¤„çš„ç¯å¢ƒ, ç›´æ¥è¾“å‡ºä¸‹ä¸€æ­¥è¦é‡‡å–çš„å„ç§åŠ¨ä½œçš„æ¦‚ç‡, ç„¶åæ ¹æ®æ¦‚ç‡é‡‡å–è¡ŒåŠ¨, æ‰€ä»¥æ¯ç§åŠ¨ä½œéƒ½æœ‰å¯èƒ½è¢«é€‰ä¸­, åªæ˜¯å¯èƒ½æ€§ä¸åŒ. è€ŒåŸºäºä»·å€¼çš„æ–¹æ³•è¾“å‡ºåˆ™æ˜¯æ‰€æœ‰åŠ¨ä½œçš„ä»·å€¼, æˆ‘ä»¬ä¼šæ ¹æ®æœ€é«˜ä»·å€¼æ¥é€‰ç€åŠ¨ä½œ, ç›¸æ¯”åŸºäºæ¦‚ç‡çš„æ–¹æ³•, åŸºäºä»·å€¼çš„å†³ç­–éƒ¨åˆ†æ›´ä¸ºé“å®š, æ¯«ä¸ç•™æƒ…, å°±é€‰ä»·å€¼æœ€é«˜çš„, è€ŒåŸºäºæ¦‚ç‡çš„, å³ä½¿æŸä¸ªåŠ¨ä½œçš„æ¦‚ç‡æœ€é«˜, ä½†æ˜¯è¿˜æ˜¯ä¸ä¸€å®šä¼šé€‰åˆ°ä»–.</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210312210405206.png" alt="image-20210312210405206"></p>
<p>å…¶ä¸­policy-basedä¸­çš„å…¸å‹ç®—æ³•æœ‰Policy Gradientsï¼Œvalue-basedçš„å…¸å‹ç®—æ³•æœ‰Q-learningã€SARSAã€DQNï¼Œä¸¤è€…é‡åˆçš„å…¸å‹æ¨¡å‹æœ‰ACã€A2Cã€A3C</p>
<span id="more"></span>

<p><strong>2.åœ¨çº¿å­¦ä¹ ï¼ˆon-policyï¼‰å’Œç¦»çº¿å­¦ä¹ ï¼ˆoff-policyï¼‰</strong></p>
<p>æ‰€è°“åœ¨çº¿å­¦ä¹ ï¼ˆon-policyï¼‰, å°±æ˜¯æŒ‡æˆ‘å¿…é¡»æœ¬äººåœ¨åœº, å¹¶ä¸”ä¸€å®šæ˜¯æœ¬äººè¾¹ç©è¾¹å­¦ä¹ , å­¦ä¹ è€…ä¸ç¯å¢ƒå¿…é¡»äº§ç”Ÿå®é™…çš„äº¤äº’ã€‚</p>
<p>è€Œç¦»çº¿å­¦ä¹ ï¼ˆoff-policyï¼‰æ˜¯ä½ å¯ä»¥é€‰æ‹©è‡ªå·±ç©, ä¹Ÿå¯ä»¥é€‰æ‹©çœ‹ç€åˆ«äººç©, é€šè¿‡çœ‹åˆ«äººç©æ¥å­¦ä¹ åˆ«äººçš„è¡Œä¸ºå‡†åˆ™ã€‚</p>
<p>on-policyçš„å…¸å‹ç®—æ³•æ˜¯SARSAï¼Œ off-policyçš„å…¸å‹ç®—æ³•æ˜¯Q-learningã€DQNã€‚</p>
<p>on-policyæ˜¯çš„å­¦ä¹ è€…å¿…å­¦è¿›è¡Œå®Œä¸€ç³»åˆ—å®é™…åŠ¨ä½œåæ‰èƒ½äº§ç”Ÿæ ·æœ¬ï¼Œè¿™æ ·æ•ˆç‡å¾€å¾€è¾ƒæ…¢ã€‚off-policyå¯ä»¥ä»ä»¥å¾€çš„ç»éªŒæˆ–åˆ«äººçš„åŠ¨ä½œå¼€å­¦ä¹ ï¼Œæ•ˆç‡å¾€å¾€æ¯”è¾ƒé«˜ã€‚</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210312210627505.png" alt="image-20210312210627505"></p>
<p><strong>3.model-basedå’Œmodel-free</strong><br>å¯ä»¥å°†æ‰€æœ‰å¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•åˆ†ä¸ºç†ä¸ç†è§£æ‰€å¤„ç¯å¢ƒ,å¦‚æœæˆ‘ä»¬ä¸å°è¯•å»ç†è§£ç¯å¢ƒ, ç¯å¢ƒç»™äº†æˆ‘ä»¬ä»€ä¹ˆå°±æ˜¯ä»€ä¹ˆ. æˆ‘ä»¬å°±æŠŠè¿™ç§æ–¹æ³•å«åš model-free, è¿™é‡Œçš„ model å°±æ˜¯ç”¨æ¨¡å‹æ¥è¡¨ç¤ºç¯å¢ƒ, é‚£ç†è§£äº†ç¯å¢ƒä¹Ÿå°±æ˜¯å­¦ä¼šäº†ç”¨ä¸€ä¸ªæ¨¡å‹æ¥ä»£è¡¨ç¯å¢ƒ, æ‰€ä»¥è¿™ç§å°±æ˜¯ model-based æ–¹æ³•.</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210312210824998.png" alt="image-20210312210824998"></p>
<h4 id="SARSAç®—æ³•åŸç†"><a href="#SARSAç®—æ³•åŸç†" class="headerlink" title="SARSAç®—æ³•åŸç†"></a>SARSAç®—æ³•åŸç†</h4><p>å¼ºåŒ–å­¦ä¹ çš„ä¸»è¦åŠŸèƒ½å°±æ˜¯è®©agentå­¦ä¹ å°½å¯èƒ½å¥½çš„åŠ¨ä½œactionï¼Œä½¿å…¶åç»­è·å¾—çš„å¥–åŠ±å°½å¯èƒ½çš„å¤§ã€‚</p>
<p>å‡è®¾åœ¨æ—¶åˆ»tæ—¶ï¼Œå¤„äºçŠ¶æ€é•¿æœŸå¥–åŠ±ä¸ºï¼š<br><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/2020032311212617.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210312211035990.png" alt="image-20210312211035990"><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210312211102633.png" alt="image-20210312211102633"></p>
<p> <img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210312213327171.png" alt="image-20210312213327171"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210312213401080.png" alt="image-20210312213401080"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210312213418619.png" alt="image-20210312213418619"></p>
<h4 id="äºŒã€SARSAä»£ç "><a href="#äºŒã€SARSAä»£ç " class="headerlink" title="äºŒã€SARSAä»£ç "></a>äºŒã€SARSAä»£ç </h4><p>æ­¤å¤„ç›´æ¥å‚è€ƒè«çƒ¦pythonçš„<a target="_blank" rel="noopener" href="https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/1-1-A-RL/">å¼ºåŒ–å­¦ä¹ æ•™ç¨‹</a>è¿›è¡Œä»£ç ç¼–å†™ï¼Œåœ¨åŸºç¡€ä¸Šè¯´æ˜æ¯ä¸€è¡Œä»£ç çš„ç”¨é€”</p>
<p>1.environmentçš„ç¼–å†™<br>é¦–å…ˆRLéœ€è¦ä¸€ä¸ªç¯å¢ƒï¼Œå› ä¸ºæˆ‘ä»¬æ§åˆ¶ä¸äº†ç¯å¢ƒï¼ˆæ¯”å¦‚ä¸‹å›´æ£‹æ—¶æˆ‘ä»¬ä¸ä¸èƒ½æ”¹å˜æ£‹ç›˜çš„å¤§å°ï¼Œä½•è½å­æ–¹å¼ï¼Œåªèƒ½åªèƒ½åœ¨èŒƒå›´å†…è½åœ¨çº¿ä¸çº¿ä¹‹é—´çš„äº¤å‰ç‚¹ä¸Šï¼‰ï¼Œè¿™ä¸ªç¯å¢ƒæ˜¯ä¸å¯ä»¥æ”¹å˜çš„ï¼Œå› æ­¤åé¢çš„Q-learningä¹Ÿå°†æ²¿ç”¨æ­¤ç¯å¢ƒã€‚é€šå¸¸ä¸åŒçš„é—®é¢˜æœ‰ä¸åŒç¯å¢ƒï¼Œæˆ‘ä»¬çœŸæ­£éœ€è¦å…³æ³¨çš„æ˜¯agentå³ç®—æ³•é€»è¾‘çš„ç¼–å†™ã€‚<br>æ­¤å¤„ä»¥èµ°æ–¹æ ¼ä¸ºä¾‹ç¼–å†™ä¸€ä¸ªenvironment</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210312215227492.png" alt="image-20210312215227492"></p>
<p>maze_env</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Reinforcement learning maze example.</span></span><br><span class="line"><span class="string">Red rectangle:          explorer.</span></span><br><span class="line"><span class="string">Black rectangles:       hells       [reward = -1].</span></span><br><span class="line"><span class="string">Yellow bin circle:      paradise    [reward = +1].</span></span><br><span class="line"><span class="string">All other states:       ground      [reward = 0].</span></span><br><span class="line"><span class="string">This script is the environment part of this example. The RL is in RL_brain.py.</span></span><br><span class="line"><span class="string">View more on my tutorial page: https://morvanzhou.github.io/tutorials/</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">if</span> sys.version_info.major == <span class="number">2</span>:</span><br><span class="line">    <span class="keyword">import</span> Tkinter <span class="keyword">as</span> tk</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">import</span> tkinter <span class="keyword">as</span> tk</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">UNIT = <span class="number">40</span>   <span class="comment"># pixels</span></span><br><span class="line">MAZE_H = <span class="number">4</span>  <span class="comment"># grid height</span></span><br><span class="line">MAZE_W = <span class="number">4</span>  <span class="comment"># grid width</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Maze</span>(tk.Tk, <span class="built_in">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Maze, self).__init__()</span><br><span class="line">        self.action_space = [<span class="string">&#x27;u&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;l&#x27;</span>, <span class="string">&#x27;r&#x27;</span>]</span><br><span class="line">        self.n_actions = <span class="built_in">len</span>(self.action_space)</span><br><span class="line">        self.title(<span class="string">&#x27;maze&#x27;</span>)</span><br><span class="line">        self.geometry(<span class="string">&#x27;&#123;0&#125;x&#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(MAZE_H * UNIT, MAZE_H * UNIT))</span><br><span class="line">        self._build_maze()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_maze</span>(<span class="params">self</span>):</span><br><span class="line">        self.canvas = tk.Canvas(self, bg=<span class="string">&#x27;white&#x27;</span>,</span><br><span class="line">                           height=MAZE_H * UNIT,</span><br><span class="line">                           width=MAZE_W * UNIT)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># create grids</span></span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, MAZE_W * UNIT, UNIT):</span><br><span class="line">            x0, y0, x1, y1 = c, <span class="number">0</span>, c, MAZE_H * UNIT</span><br><span class="line">            self.canvas.create_line(x0, y0, x1, y1)</span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, MAZE_H * UNIT, UNIT):</span><br><span class="line">            x0, y0, x1, y1 = <span class="number">0</span>, r, MAZE_W * UNIT, r</span><br><span class="line">            self.canvas.create_line(x0, y0, x1, y1)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># create origin</span></span><br><span class="line">        origin = np.array([<span class="number">20</span>, <span class="number">20</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># hell</span></span><br><span class="line">        hell1_center = origin + np.array([UNIT * <span class="number">2</span>, UNIT])</span><br><span class="line">        self.hell1 = self.canvas.create_rectangle(</span><br><span class="line">            hell1_center[<span class="number">0</span>] - <span class="number">15</span>, hell1_center[<span class="number">1</span>] - <span class="number">15</span>,</span><br><span class="line">            hell1_center[<span class="number">0</span>] + <span class="number">15</span>, hell1_center[<span class="number">1</span>] + <span class="number">15</span>,</span><br><span class="line">            fill=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        <span class="comment"># hell</span></span><br><span class="line">        hell2_center = origin + np.array([UNIT, UNIT * <span class="number">2</span>])</span><br><span class="line">        self.hell2 = self.canvas.create_rectangle(</span><br><span class="line">            hell2_center[<span class="number">0</span>] - <span class="number">15</span>, hell2_center[<span class="number">1</span>] - <span class="number">15</span>,</span><br><span class="line">            hell2_center[<span class="number">0</span>] + <span class="number">15</span>, hell2_center[<span class="number">1</span>] + <span class="number">15</span>,</span><br><span class="line">            fill=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># create oval</span></span><br><span class="line">        oval_center = origin + UNIT * <span class="number">2</span></span><br><span class="line">        self.oval = self.canvas.create_oval(</span><br><span class="line">            oval_center[<span class="number">0</span>] - <span class="number">15</span>, oval_center[<span class="number">1</span>] - <span class="number">15</span>,</span><br><span class="line">            oval_center[<span class="number">0</span>] + <span class="number">15</span>, oval_center[<span class="number">1</span>] + <span class="number">15</span>,</span><br><span class="line">            fill=<span class="string">&#x27;yellow&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># create red rect</span></span><br><span class="line">        self.rect = self.canvas.create_rectangle(</span><br><span class="line">            origin[<span class="number">0</span>] - <span class="number">15</span>, origin[<span class="number">1</span>] - <span class="number">15</span>,</span><br><span class="line">            origin[<span class="number">0</span>] + <span class="number">15</span>, origin[<span class="number">1</span>] + <span class="number">15</span>,</span><br><span class="line">            fill=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># pack all</span></span><br><span class="line">        self.canvas.pack()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>):</span><br><span class="line">        self.update()</span><br><span class="line">        time.sleep(<span class="number">0.5</span>)</span><br><span class="line">        self.canvas.delete(self.rect)</span><br><span class="line">        origin = np.array([<span class="number">20</span>, <span class="number">20</span>])</span><br><span class="line">        self.rect = self.canvas.create_rectangle(</span><br><span class="line">            origin[<span class="number">0</span>] - <span class="number">15</span>, origin[<span class="number">1</span>] - <span class="number">15</span>,</span><br><span class="line">            origin[<span class="number">0</span>] + <span class="number">15</span>, origin[<span class="number">1</span>] + <span class="number">15</span>,</span><br><span class="line">            fill=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        <span class="comment"># return observation</span></span><br><span class="line">        <span class="keyword">return</span> self.canvas.coords(self.rect)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self, action</span>):</span><br><span class="line">        s = self.canvas.coords(self.rect)</span><br><span class="line">        base_action = np.array([<span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> action == <span class="number">0</span>:   <span class="comment"># up</span></span><br><span class="line">            <span class="keyword">if</span> s[<span class="number">1</span>] &gt; UNIT:</span><br><span class="line">                base_action[<span class="number">1</span>] -= UNIT</span><br><span class="line">        <span class="keyword">elif</span> action == <span class="number">1</span>:   <span class="comment"># down</span></span><br><span class="line">            <span class="keyword">if</span> s[<span class="number">1</span>] &lt; (MAZE_H - <span class="number">1</span>) * UNIT:</span><br><span class="line">                base_action[<span class="number">1</span>] += UNIT</span><br><span class="line">        <span class="keyword">elif</span> action == <span class="number">2</span>:   <span class="comment"># right</span></span><br><span class="line">            <span class="keyword">if</span> s[<span class="number">0</span>] &lt; (MAZE_W - <span class="number">1</span>) * UNIT:</span><br><span class="line">                base_action[<span class="number">0</span>] += UNIT</span><br><span class="line">        <span class="keyword">elif</span> action == <span class="number">3</span>:   <span class="comment"># left</span></span><br><span class="line">            <span class="keyword">if</span> s[<span class="number">0</span>] &gt; UNIT:</span><br><span class="line">                base_action[<span class="number">0</span>] -= UNIT</span><br><span class="line"></span><br><span class="line">        self.canvas.move(self.rect, base_action[<span class="number">0</span>], base_action[<span class="number">1</span>])  <span class="comment"># move agent</span></span><br><span class="line"></span><br><span class="line">        s_ = self.canvas.coords(self.rect)  <span class="comment"># next state</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># reward function</span></span><br><span class="line">        <span class="keyword">if</span> s_ == self.canvas.coords(self.oval):</span><br><span class="line">            reward = <span class="number">1</span></span><br><span class="line">            done = <span class="literal">True</span></span><br><span class="line">            s_ = <span class="string">&#x27;terminal&#x27;</span></span><br><span class="line">        <span class="keyword">elif</span> s_ <span class="keyword">in</span> [self.canvas.coords(self.hell1), self.canvas.coords(self.hell2)]:</span><br><span class="line">            reward = -<span class="number">1</span></span><br><span class="line">            done = <span class="literal">True</span></span><br><span class="line">            s_ = <span class="string">&#x27;terminal&#x27;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            reward = <span class="number">0</span></span><br><span class="line">            done = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> s_, reward, done</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">render</span>(<span class="params">self</span>):</span><br><span class="line">        time.sleep(<span class="number">0.1</span>)</span><br><span class="line">        self.update()</span><br><span class="line">        </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">update</span>():</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        s = env.reset()</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            env.render()</span><br><span class="line">            a = <span class="number">1</span></span><br><span class="line">            s, r, done = env.step(a)</span><br><span class="line">            <span class="keyword">if</span> done:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    env = Maze()</span><br><span class="line">    env.after(<span class="number">100</span>, update)</span><br><span class="line">    env.mainloop()</span><br></pre></td></tr></table></figure>

<p><strong>agent</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> maze_env <span class="keyword">import</span> Maze    <span class="comment">#å³ä¸ºä¸Šé¢çš„environment</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment">#RLçš„çˆ¶ç±»å®šä¹‰</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RL</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="comment">#åˆå§‹åŒ–</span></span><br><span class="line">    <span class="comment">#actionsä¸ºå¯é€‰åŠ¨ä½œï¼Œ learning_rateä¸ºå­¦ä¹ ç‡ï¼Œreward_decayä¸ºä¼ é€’å¥–åŠ±æ˜¯çš„é€’å‡ç³»æ•°gammaï¼Œ1-e_greedä¸ºéšæœºé€‰æ‹©å…¶ä»–åŠ¨ä½œçš„æ¦‚ç‡</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, actions, learning_rate=<span class="number">0.01</span>, reward_decay=<span class="number">0.9</span>, e_greedy=<span class="number">0.9</span></span>):</span><br><span class="line">        self.actions = actions</span><br><span class="line">        self.lr = learning_rate</span><br><span class="line">        self.gamma = reward_decay</span><br><span class="line">        self.epsilon = e_greedy</span><br><span class="line">        <span class="comment">#åˆå§‹åŒ–qtableï¼Œè¡Œä¸ºobservationçš„stateï¼Œ åˆ—ä¸ºå½“å‰çŠ¶æ€å¯ä»¥é€‰æ‹©çš„actionï¼ˆå¯¹äºæ‰€æœ‰åˆ—ï¼Œå¯ä»¥é€‰æ‹©çš„actionä¸€æ ·ï¼‰</span></span><br><span class="line">        self.q_table = pd.DataFrame(columns = self.actions, dtype=np.float64)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">choose_action</span>(<span class="params">self, observation</span>):</span><br><span class="line">        self.check_state_exist(observation)  <span class="comment">#æ£€æŸ¥å½“å‰çŠ¶æ€æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨å°±æ·»åŠ è¿™ä¸ªçŠ¶æ€</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> np.random.uniform() &lt; self.epsilon:</span><br><span class="line">            state_action = self.q_table.loc[observation, :]  <span class="comment">#æ‰¾åˆ°å½“å‰çŠ¶æ€å¯ä»¥é€‰æ‹©çš„åŠ¨ä½œ</span></span><br><span class="line">            <span class="comment">#ç”±äºåˆå§‹åŒ–æˆ–æ›´æ–°åä¸€ä¸ªçŠ¶æ€ä¸‹çš„åŠ¨ä½œå€¼å¯èƒ½æ˜¯ç›¸åŒçš„ï¼Œä¸ºäº†é¿å…æ¯æ¬¡éƒ½é€‰æ‹©ç›¸åŒåŠ¨ä½œï¼Œç”¨random.choiceåœ¨å€¼æœ€å¤§çš„actionä¸­æŸåŠé€‰æ‹©ä¸€ä¸ª</span></span><br><span class="line">            action = np.random.choice(state_action[state_action==np.<span class="built_in">max</span>(state_action)].index)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            action = np.random.choice(self.actions)   <span class="comment">#0.1çš„å‡ ç‡éšæœºé€‰æ‹©åŠ¨ä½œ</span></span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">check_state_exist</span>(<span class="params">self, state</span>):</span><br><span class="line">        <span class="keyword">if</span> state <span class="keyword">not</span> <span class="keyword">in</span> self.q_table.index:</span><br><span class="line">            <span class="comment">#è‹¥æ‰¾ä¸åˆ°è¯¥obversationçš„è½¬æ€ï¼Œåˆ™æ·»åŠ è¯¥çŠ¶æ€åˆ°æ–°çš„qtable</span></span><br><span class="line">            <span class="comment">#æ–°çš„stateçš„åŠ¨ä½œçš„qåˆå§‹å€¼èµ‹å€¼ä¸º0ï¼Œåˆ—åä¸ºdataframeçš„åˆ—åï¼Œindexä¸ºstate</span></span><br><span class="line">            self.q_table = self.q_table.append(pd.Series([<span class="number">0</span>]*<span class="built_in">len</span>(self.actions), index=self.q_table.columns, name=state))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#ä¸åŒæ–¹å¼çš„å­¦ä¹ æ–¹æ³•ä¸åŒï¼Œç”¨å¯å˜å‚æ•°ï¼Œç›´æ¥pass</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">learning</span>(<span class="params">self, *args</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SarsaTable</span>(<span class="title class_ inherited__">RL</span>):  <span class="comment">#ç»§æ‰¿ä¸Šé¢çš„RL</span></span><br><span class="line">    <span class="comment">#åˆå§‹åŒ–</span></span><br><span class="line">    <span class="comment">#å‚æ•°è‡ªå·±å®šä¹‰ï¼Œå«ä¹‰ç»§æ‰¿çˆ¶ç±»RL</span></span><br><span class="line">    <span class="comment">#ç±»æ–¹æ³•choose_actionã€check_state_existè‡ªåŠ¨ç»§æ‰¿RLï¼Œå‚æ•°ä¸å˜</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, actions, learning_rate=<span class="number">0.01</span>, reward_decay=<span class="number">0.9</span>, e_greedy=<span class="number">0.9</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(SarsaTable, self).__init__(actions, learning_rate, reward_decay, e_greedy)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">learning</span>(<span class="params">self, s, a,r, s_, a_</span>):</span><br><span class="line">        self.check_state_exist(s_)   <span class="comment">#æ£€æŸ¥åŠ¨ä½œåçŠ¶æ€s_æ˜¯å¦å­˜åœ¨</span></span><br><span class="line">        </span><br><span class="line">        q_old = self.q_table.loc[s, a]  <span class="comment">#æ—§çš„q[s,a]å€¼</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> s_!=<span class="string">&#x27;terminal&#x27;</span>:</span><br><span class="line">            <span class="comment">#å–ä¸‹ä¸ªçŠ¶æ€s_å’ŒåŠ¨ä½œa_ä¸‹qå€¼</span></span><br><span class="line">            q_predict = self.q_table.loc[s_, a_]</span><br><span class="line">            q_new = r+self.gamma*q_predict   <span class="comment">#è®¡ç®—æ–°çš„å€¼</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            q_new = r</span><br><span class="line">        </span><br><span class="line">        self.q_table.loc[s,a] = q_old - self.lr*(q_new - q_old)    <span class="comment">#æ ¹æ®æ›´æ–°å…¬å¼æ›´æ–°ï¼Œç±»ä¼¼äºæ¢¯åº¦ä¸‹é™</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">update</span>():</span><br><span class="line">    <span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        <span class="comment">#åˆå§‹åŒ–ç¯å¢ƒ</span></span><br><span class="line">        observation = env.reset()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#æ ¹æ®å½“å‰çŠ¶æ€é€‰è¡Œä¸º</span></span><br><span class="line">        action = RL.choose_action(<span class="built_in">str</span>(observation))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="comment"># åˆ·æ–°ç¯å¢ƒ</span></span><br><span class="line">            env.render()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># åœ¨ç¯å¢ƒä¸­é‡‡å–è¡Œä¸º, è·å¾—ä¸‹ä¸€ä¸ª state_ (obervation_), reward, å’Œæ˜¯å¦ç»ˆæ­¢</span></span><br><span class="line">            observation_, reward, done = env.step(action)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#æ ¹æ®observation_é€‰æ‹©observation_ä¸‹åº”è¯¥é€‰æ‹©çš„åŠ¨ä½œaction_</span></span><br><span class="line">            action_ = RL.choose_action(<span class="built_in">str</span>(observation_))</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#ä»å½“å‰çŠ¶æ€stateï¼Œå½“å‰åŠ¨ä½œactionï¼Œå¥–åŠ±rï¼Œæ‰§è¡ŒåŠ¨ä½œåstate_ï¼Œstate_ä¸‹çš„action_,(s,a,r,s,a)</span></span><br><span class="line">            RL.learning(<span class="built_in">str</span>(observation), action, reward, <span class="built_in">str</span>(observation_), action_)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># å°†ä¸‹ä¸€ä¸ªå½“æˆä¸‹ä¸€æ­¥çš„ state (observation) and actionã€‚</span></span><br><span class="line">            <span class="comment">#ä¸qlearningçš„å´åˆ«æ˜¯sarsaåœ¨observation_ä¸‹çœŸæ­£æ‰§è¡Œäº†åŠ¨ä½œaction_ï¼Œä¾›ä¸‹æ¬¡ä½¿ç”¨</span></span><br><span class="line">            <span class="comment">#è€Œqlearningä¸­ä¸‹æ¬¡çŠ¶æ€observation_æ—¶è¿˜è¦é‡æ–°é€‰æ‹©action_</span></span><br><span class="line">            observation = observation_</span><br><span class="line">            action = action_</span><br><span class="line">            </span><br><span class="line">             <span class="comment"># ç»ˆæ­¢æ—¶è·³å‡ºå¾ªç¯</span></span><br><span class="line">        	<span class="keyword">if</span> done:</span><br><span class="line">            	<span class="keyword">break</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># å¤§å¾ªç¯å®Œæ¯•</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;game over&#x27;</span>)</span><br><span class="line">    env.destroy()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    env = Maze()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Sarsaå’ŒSarsaLambdaçš„è°ƒç”¨æ–¹å¼ä¸€æ¨¡ä¸€æ ·</span></span><br><span class="line">    <span class="comment">#RL = SarsaTable(actions=list(range(env.n_actions)))</span></span><br><span class="line">    RL = SarsaLambdaTable(actions=<span class="built_in">list</span>(<span class="built_in">range</span>(env.n_actions)))</span><br><span class="line"></span><br><span class="line">    env.after(<span class="number">100</span>, update)</span><br><span class="line">    env.mainloop()</span><br></pre></td></tr></table></figure>



<h4 id="Q-learningã€"><a href="#Q-learningã€" class="headerlink" title="Q-learningã€"></a>Q-learningã€</h4><p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210315201907446.png" alt="image-20210315201907446"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/20200323154100203.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210315202102199.png" alt="image-20210315202102199"></p>
<p>ç”¨åŒä¸€ä¸ªenv</p>
<p>qlearnning-agent</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> maze_env <span class="keyword">import</span> Maze</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># RLçš„çˆ¶ç±»å®šä¹‰</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RL</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="comment"># åˆå§‹åŒ–</span></span><br><span class="line">    <span class="comment"># actionsä¸ºå¯é€‰åŠ¨ä½œï¼Œ learning_rateä¸ºå­¦ä¹ ç‡ï¼Œreward_decayä¸ºä¼ é€’å¥–åŠ±æ˜¯çš„é€’å‡ç³»æ•°gammaï¼Œ1-e_greedä¸ºéšæœºé€‰æ‹©å…¶ä»–åŠ¨ä½œçš„æ¦‚ç‡</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, actions, learning_rate=<span class="number">0.01</span>, reward_decay=<span class="number">0.9</span>, e_greedy=<span class="number">0.9</span></span>):</span><br><span class="line">        self.actions = actions</span><br><span class="line">        self.lr = learning_rate</span><br><span class="line">        self.gamma = reward_decay</span><br><span class="line">        self.epsilon = e_greedy</span><br><span class="line">        <span class="comment"># åˆå§‹åŒ–qtableï¼Œè¡Œä¸ºobservationçš„stateï¼Œ åˆ—ä¸ºå½“å‰çŠ¶æ€å¯ä»¥é€‰æ‹©çš„actionï¼ˆå¯¹äºæ‰€æœ‰åˆ—ï¼Œå¯ä»¥é€‰æ‹©çš„actionä¸€æ ·ï¼‰</span></span><br><span class="line">        self.q_table = pd.DataFrame(columns=self.actions, dtype=np.float64)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">choose_action</span>(<span class="params">self, observation</span>):</span><br><span class="line">        self.check_state_exist(observation)  <span class="comment"># æ£€æŸ¥å½“å‰çŠ¶æ€æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨å°±æ·»åŠ è¿™ä¸ªçŠ¶æ€</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> np.random.uniform() &lt; self.epsilon:</span><br><span class="line">            state_action = self.q_table.loc[observation, :]  <span class="comment"># æ‰¾åˆ°å½“å‰çŠ¶æ€å¯ä»¥é€‰æ‹©çš„åŠ¨ä½œ</span></span><br><span class="line">            <span class="comment"># ç”±äºåˆå§‹åŒ–æˆ–æ›´æ–°åä¸€ä¸ªçŠ¶æ€ä¸‹çš„åŠ¨ä½œå€¼å¯èƒ½æ˜¯ç›¸åŒçš„ï¼Œä¸ºäº†é¿å…æ¯æ¬¡éƒ½é€‰æ‹©ç›¸åŒåŠ¨ä½œï¼Œç”¨random.choiceåœ¨å€¼æœ€å¤§çš„actionä¸­æŸåŠé€‰æ‹©ä¸€ä¸ª</span></span><br><span class="line">            action = np.random.choice(state_action[state_action == np.<span class="built_in">max</span>(state_action)].index)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            action = np.random.choice(self.actions)  <span class="comment"># 0.1çš„å‡ ç‡éšæœºé€‰æ‹©åŠ¨ä½œ</span></span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">check_state_exist</span>(<span class="params">self, state</span>):</span><br><span class="line">        <span class="keyword">if</span> state <span class="keyword">not</span> <span class="keyword">in</span> self.q_table.index:</span><br><span class="line">            <span class="comment"># è‹¥æ‰¾ä¸åˆ°è¯¥obversationçš„è½¬æ€ï¼Œåˆ™æ·»åŠ è¯¥çŠ¶æ€åˆ°æ–°çš„qtable</span></span><br><span class="line">            <span class="comment"># æ–°çš„stateçš„åŠ¨ä½œçš„qåˆå§‹å€¼èµ‹å€¼ä¸º0ï¼Œåˆ—åä¸ºdataframeçš„åˆ—åï¼Œindexä¸ºstate</span></span><br><span class="line">            self.q_table = self.q_table.append(</span><br><span class="line">                pd.Series([<span class="number">0</span>] * <span class="built_in">len</span>(self.actions), index=self.q_table.columns, name=state))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ä¸åŒæ–¹å¼çš„å­¦ä¹ æ–¹æ³•ä¸åŒï¼Œç”¨å¯å˜å‚æ•°ï¼Œç›´æ¥pass</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">learning</span>(<span class="params">self, *args</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># QLearningç»§æ‰¿RL</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QLearningTable</span>(<span class="title class_ inherited__">RL</span>):</span><br><span class="line">    <span class="comment"># åˆå§‹åŒ–</span></span><br><span class="line">    <span class="comment"># å‚æ•°è‡ªå·±å®šä¹‰ï¼Œå«ä¹‰ç»§æ‰¿çˆ¶ç±»RL</span></span><br><span class="line">    <span class="comment"># ç±»æ–¹æ³•choose_actionã€check_state_existè‡ªåŠ¨ç»§æ‰¿RLï¼Œå‚æ•°ä¸å˜</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, actions, learning_rate=<span class="number">0.01</span>, reward_decay=<span class="number">0.9</span>, e_greedy=<span class="number">0.9</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(QLearningTable, self).__init__(actions, learning_rate, reward_decay, e_greedy)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># æ ¹ç»å½“å‰è§‚å¯ŸçŠ¶æ€sï¼Œé€‰æ‹©åŠ¨ä½œaï¼Œé€‰æ‹©åŠ¨ä½œåçš„å¥–åŠ±rï¼Œå’Œæ‰§è¡ŒåŠ¨ä½œåçš„çŠ¶æ€s_ï¼Œæ¥æ›´æ–°qtable</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">learning</span>(<span class="params">self, s, a, r, s_</span>):</span><br><span class="line">        self.check_state_exist(s_)  <span class="comment"># æ£€æŸ¥åŠ¨ä½œåçŠ¶æ€s_æ˜¯å¦å­˜åœ¨</span></span><br><span class="line"></span><br><span class="line">        q_old = self.q_table.loc[s, a]  <span class="comment"># æ—§çš„q[s,a]å€¼</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> s_ != <span class="string">&#x27;terminal&#x27;</span>:</span><br><span class="line">            <span class="comment"># ä¸‹ä¸ªçŠ¶æ€ä¸‹æœ€å¤§çš„å€¼</span></span><br><span class="line">            max_s_ = self.q_table.loc[s_, :].<span class="built_in">max</span>()</span><br><span class="line">            q_new = r + self.gamma * max_s_  <span class="comment"># è®¡ç®—æ–°çš„å€¼</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            q_new = r</span><br><span class="line"></span><br><span class="line">        self.q_table.loc[s, a] = q_old - self.lr * (q_new - q_old)  <span class="comment"># æ ¹æ®æ›´æ–°å…¬å¼æ›´æ–°ï¼Œç±»ä¼¼äºæ¢¯åº¦ä¸‹é™</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">update</span>():</span><br><span class="line">    <span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        <span class="comment"># åˆå§‹åŒ– state çš„è§‚æµ‹å€¼</span></span><br><span class="line">        observation = env.reset()  <span class="comment"># æ¯è½®è®­ç»ƒéƒ½è¦åˆå§‹åŒ–è§‚æµ‹å€¼ï¼Œå³å›åˆ°åŸç‚¹çŠ¶æ€</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            env.render()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># RL å¤§è„‘æ ¹æ® state çš„è§‚æµ‹å€¼æŒ‘é€‰ action</span></span><br><span class="line">            action = RL.choose_action(<span class="built_in">str</span>(observation))  <span class="comment"># qlearningé‡‡ç”¨greeedæ–¹æ³•ï¼Œé€‰æ‹©qå€¼æœ€å¤§çš„action</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># æ¢ç´¢è€…åœ¨ç¯å¢ƒä¸­å®æ–½è¿™ä¸ª action, å¹¶å¾—åˆ°ç¯å¢ƒè¿”å›çš„ä¸‹ä¸€ä¸ª state è§‚æµ‹å€¼, reward å’Œ done (æ˜¯å¦æ˜¯æ‰ä¸‹åœ°ç‹±æˆ–è€…å‡ä¸Šå¤©å ‚)</span></span><br><span class="line">            <span class="comment"># æ˜¯æ ¹æ®å½“å‰é€‰æ‹©åŠ¨ä½œï¼Œè§‚å¯Ÿåˆ°çš„é‡‡å–åŠ¨ä½œåçš„çŠ¶æ€å’Œå¥–åŠ±</span></span><br><span class="line">            observation_, reward, done = env.step(action)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># RL ä»è¿™ä¸ªåºåˆ— (state, action, reward, state_) ä¸­å­¦ä¹ </span></span><br><span class="line">            <span class="comment"># æ ¹ç»æ—§observationçš„qå€¼ï¼Œå’Œé‡‡å–åŠ¨ä½œï¼Œä»¥åŠå¥–åŠ±å’Œé‡‡å–åŠ¨ä½œåçš„observation_çš„æœ€å¤§qå€¼è¿›è¡Œæ›´æ–°</span></span><br><span class="line">            RL.learning(<span class="built_in">str</span>(observation), action, reward, <span class="built_in">str</span>(observation_))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># å°†ä¸‹ä¸€ä¸ª state çš„å€¼ä¼ åˆ°ä¸‹ä¸€æ¬¡å¾ªç¯</span></span><br><span class="line">            observation = observation_</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> done:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ç»“æŸæ¸¸æˆå¹¶å…³é—­çª—å£</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;game over&#x27;</span>)</span><br><span class="line">    env.destroy()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># å®šä¹‰ç¯å¢ƒ env å’Œ RL æ–¹å¼</span></span><br><span class="line">    env = Maze()</span><br><span class="line">    RL = QLearningTable(actions=<span class="built_in">list</span>(<span class="built_in">range</span>(env.n_actions)))</span><br><span class="line">    <span class="comment"># å¼€å§‹å¯è§†åŒ–ç¯å¢ƒ env</span></span><br><span class="line">    env.after(<span class="number">100</span>, update)</span><br><span class="line">    env.mainloop()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>å”¯ä¸€ä¸åŒæ˜¯on -&gt;off</p>
<p>å¹¶æœªçœŸæ­£æ‰§è¡Œaâ€™ï¼Œè€Œæ˜¯é€‰æ‹©æ‰€æœ‰aä¸­Qå€¼æœ€å¤§çš„ä¸€é¡¹ï¼›</p>
<h5 id="DQN"><a href="#DQN" class="headerlink" title="DQN"></a>DQN</h5><p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210315202734362.png" alt="image-20210315202734362"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210315203248027.png" alt="image-20210315203248027"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210315203406102.png" alt="image-20210315203406102"></p>
<p>DQNçš„ç®—æ³•</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/20200323172714471.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210315204554812.png" alt="image-20210315204554812"></p>
<h5 id="å­¦ä¹ ç­–ç•¥ï¼šobservation"><a href="#å­¦ä¹ ç­–ç•¥ï¼šobservation" class="headerlink" title="å­¦ä¹ ç­–ç•¥ï¼šobservation"></a>å­¦ä¹ ç­–ç•¥ï¼šobservation</h5><p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210315213257698.png" alt="image-20210315213257698"></p>
<p><strong>æ›´æ–°æ–¹å¼ä¸€</strong>ï¼šæ›´æ–°æ…¢ï¼Œéœ€è¦å°†æ‰€æœ‰çš„åŠ¨ä½œæ‰§è¡Œå®Œæ‰èƒ½æ›´æ–°</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210315205418821.png" alt="image-20210315205418821"></p>
<p><strong><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/20200323190859264.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°">æ›´æ–°æ–¹å¼äºŒ</strong>ï¼š</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/20200323191743435.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210315211111470.png" alt="image-20210315211111470"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210315211131717.png" alt="image-20210315211131717"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210315221326359.png" alt="image-20210315221326359"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210315221342578.png" alt="image-20210315221342578"></p>
<p>ä½†ä¸Šé¢ç®—æ³•ä¸­ï¼Œä¹Ÿæœ‰ä¸€äº›ä¸Q-learningä¸åŒçš„åœ°æ–¹ï¼Œè¿™æ˜¯ä½¿DQNå˜å¾—æ›´åŠ æœ‰æ•ˆå’ŒæŠ€å·§ï¼š</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210315221711848.png" alt="image-20210315221711848"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210315221729557.png" alt="image-20210315221729557"></p>
<h4 id="Dobule-DQN"><a href="#Dobule-DQN" class="headerlink" title="Dobule DQN"></a>Dobule DQN</h4><p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316191813210.png" alt="image-20210316191813210"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316193812638.png" alt="image-20210316193812638"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316193825686.png" alt="image-20210316193825686"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316193923094.png" alt="image-20210316193923094"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316193946037.png" alt="image-20210316193946037"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316194102502.png" alt="image-20210316194102502"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Double_DeepQNetwork</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="comment">#replace_target_iterä¸ºæ›´æ–°target networkçš„æ­¥æ•°ï¼Œé˜²æ­¢target networkå’Œeval networkå·®åˆ«è¿‡å¤§</span></span><br><span class="line">    <span class="comment">#memory_sizeä¸ºbufferå‚¨å­˜è®°å¿†ä¸Šçº¿ï¼Œæ–¹ä¾¿ä½¿ç”¨ä»¥å‰è®°å¿†å­¦ä¹ </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_actions, n_features,learning_rate=<span class="number">0.01</span>,reward_decay=<span class="number">0.9</span>,e_greedy=<span class="number">0.9</span>,replace_target_iter=<span class="number">300</span>,memory_size=<span class="number">500</span>,batch_size=<span class="number">32</span>,e_greedy_increment=<span class="literal">None</span>,output_graph=<span class="literal">False</span></span>):</span><br><span class="line">        self.n_actions = n_actions</span><br><span class="line">        self.n_features = n_features</span><br><span class="line">        self.lr = learning_rate</span><br><span class="line">        self.gamma = reward_decay</span><br><span class="line">        self.epsilon_max = e_greedy     <span class="comment"># epsilonåé¢å¥–åŠ±å¯¹å‰é¢çš„é€’å‡å‚æ•°</span></span><br><span class="line">        self.replace_target_iter = replace_target_iter  <span class="comment"># æ›´æ¢ target_net çš„æ­¥æ•°</span></span><br><span class="line">        self.memory_size = memory_size  <span class="comment"># è®°å¿†ä¸Šé™</span></span><br><span class="line">        self.batch_size = batch_size    <span class="comment"># æ¯æ¬¡æ›´æ–°æ—¶ä» memory é‡Œé¢å–å¤šå°‘è®°å¿†å‡ºæ¥</span></span><br><span class="line">        self.epsilon_increment = e_greedy_increment <span class="comment"># epsilon çš„å¢é‡</span></span><br><span class="line">        <span class="comment">#epsilon = 0ç­‰äº0æ—¶ï¼Œåé¢çš„å¥–åŠ±åˆ›ä¼ ä¸åˆ°å‰é¢ï¼Œå‰é¢çš„çŠ¶æ€å°±å¼€å¯éšæœºæ¢ç´¢æ¨¡å¼</span></span><br><span class="line">        self.epsilon = <span class="number">0</span> <span class="keyword">if</span> e_greedy_increment <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> self.epsilon_max <span class="comment"># æ˜¯å¦å¼€å¯æ¢ç´¢æ¨¡å¼, å¹¶é€æ­¥å‡å°‘æ¢ç´¢æ¬¡æ•°</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># è®°å½•å­¦ä¹ æ¬¡æ•° (ç”¨äºåˆ¤æ–­æ˜¯å¦æ›´æ¢ target_net å‚æ•°)</span></span><br><span class="line">        self.learn_step_counter = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># åˆå§‹åŒ–å…¨ 0 è®°å¿† [s, a, r, s_]ï¼Œ å®é™…ä¸Šfeatureä¸ºçŠ¶æ€çš„ç»´åº¦ï¼Œn_features*2åˆ†åˆ«è®°å½•så’Œs_ï¼Œ+2è®°å½•aå’Œr</span></span><br><span class="line">        self.memory = np.zeros((self.memory_size, n_features*<span class="number">2</span>+<span class="number">2</span>))</span><br><span class="line">        </span><br><span class="line">        self._build_net()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#æ›¿æ¢ target net çš„å‚æ•°</span></span><br><span class="line">        t_params = tf.get_collection(<span class="string">&#x27;target_net_params&#x27;</span>)  <span class="comment">#æå– target_net çš„å‚æ•°</span></span><br><span class="line">        e_params = tf.get_collection(<span class="string">&#x27;eval_net_params&#x27;</span>)   <span class="comment"># æå–  eval_net çš„å‚æ•°</span></span><br><span class="line">        <span class="comment">#å°†eval_networkä¸­æ¯ä¸€ä¸ªvariableçš„å€¼èµ‹å€¼ç»™target networkçš„å¯¹åº”å˜é‡</span></span><br><span class="line">        self.replace_target_op = [tf.assign(t, e) <span class="keyword">for</span> t, e <span class="keyword">in</span> <span class="built_in">zip</span>(t_params, e_params)] <span class="comment">#æ›´æ–° target_net å‚æ•°</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        self.sess = tf.Session()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> output_graph:</span><br><span class="line">            tf.summary.FileWriter(<span class="string">&quot;logs/&quot;</span>, self.sess.graph)</span><br><span class="line">        </span><br><span class="line">        self.sess.run(tf.global_variables_initializer())</span><br><span class="line">        <span class="comment">#ç”¨äºè®°å½•# è®°å½•æ‰€æœ‰ cost å˜åŒ–</span></span><br><span class="line">        self.cost_his = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#æå®æ¯…è€å¸ˆå…‹é‡çš„relpay bufferï¼Œé€šè¿‡ä»¥å¾€çš„è®°å¿†ä¸­ä¸æ–­è®­ç»ƒ</span></span><br><span class="line">    <span class="comment">#è¿™æ˜¯DQNå˜ä¸ºoff-policyçš„æ ¸å¿ƒ</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">store_transition</span>(<span class="params">self, s, a, r, s_</span>):</span><br><span class="line">        <span class="comment">#å¦‚æœDeepQNetworkä¸­å®šä¹‰äº†memory_counterï¼Œè¿›è¡Œè®°å¿†å­˜å‚¨</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(self, <span class="string">&#x27;memory_counter&#x27;</span>):</span><br><span class="line">            self.memory_counter = <span class="number">0</span></span><br><span class="line">        <span class="comment">#è®°å½•ä¸€æ¡ [s, a, r, s_] è®°å½•</span></span><br><span class="line">        transition = np.hstack((s, [a, r], s_))</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#æ€» memory å¤§å°æ˜¯å›ºå®šçš„, å¦‚æœè¶…å‡ºæ€»å¤§å°, æ—§ memory å°±è¢«æ–° memory æ›¿æ¢</span></span><br><span class="line">        index = self.memory_counter % self.memory_size  <span class="comment">#ç±»ä¼¼hashmapèµ‹å€¼æ€æƒ³</span></span><br><span class="line">        self.memory[index, :] = transition  <span class="comment">#è¿›è¡Œæ›¿æ¢</span></span><br><span class="line">        </span><br><span class="line">        self.memory_counter += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment">#å»ºç«‹ç¥ç»ç½‘ç»œ</span></span><br><span class="line">    <span class="comment">#æ­¤å¤„å»ºç«‹ä¸¤ä¸ªç”³è¯·ç½‘ç»œï¼Œä¸€ä¸ªä¸ºtarget networkï¼Œç”¨äºå¾—åˆ°qç°å®ã€‚ä¸€ä¸ªä¸ºeval_networkï¼Œç”¨äºå¾—åˆ°qä¼°è®¡</span></span><br><span class="line">    <span class="comment">#target networkå’Œeval_networkç»“æ„ä¸€æ ·ï¼Œtarget networkç”¨æ¯”è¾ƒè€çš„å‚æ•°ï¼Œeval_networkä¸ºçœŸæ­£è®­ç»ƒçš„ç¥ç»ç½‘ç»œ</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_net</span>(<span class="params">self</span>):</span><br><span class="line">        tf.reset_default_graph()  <span class="comment">#æ¸…ç©ºè®¡ç®—å›¾</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#åˆ›å»ºevalç¥ç»ç½‘ç»œ,åŠæ—¶æå‡å‚æ•°</span></span><br><span class="line">        self.s = tf.placeholder(tf.float32, [<span class="literal">None</span>, self.n_features], name=<span class="string">&#x27;s&#x27;</span>)  <span class="comment"># ç”¨æ¥æ¥æ”¶ observationï¼Œå³ç¥ç»ç½‘ç»œçš„è¾“å…¥</span></span><br><span class="line">        self.q_target = tf.placeholder(tf.float32, [<span class="literal">None</span>, self.n_actions], name=<span class="string">&#x27;Q_target&#x27;</span>) <span class="comment"># q_targetçš„å€¼, è¿™ä¸ªä¹‹åä¼šé€šè¿‡è®¡ç®—å¾—åˆ°ï¼Œç¥ç»ç½‘ç»œçš„è¾“å‡º</span></span><br><span class="line">        <span class="comment">#eval_netåŸŸä¸‹çš„å˜é‡</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;eval_net&#x27;</span>):</span><br><span class="line">            <span class="comment">#c_namesç”¨äºåœ¨ä¸€å®šæ­¥æ•°ä¹‹åæ›´æ–°target network</span></span><br><span class="line">            <span class="comment">#GLOBAL_VARIABLESä½œç”¨æ˜¯collectioné»˜è®¤åŠ å…¥æ‰€æœ‰çš„Variableå¯¹è±¡ï¼Œç”¨äºå…±äº«</span></span><br><span class="line">            c_names = [<span class="string">&#x27;eval_net_params&#x27;</span>, tf.GraphKeys.GLOBAL_VARIABLES]</span><br><span class="line">            n_l1 = <span class="number">10</span>  <span class="comment">#n_l1ä¸ºnetworkéšè—å±‚ç¥ç»å…ƒçš„ä¸ªæ•° </span></span><br><span class="line">            w_initializer = tf.random_normal_initializer(<span class="number">0.</span>,<span class="number">0.3</span>)  </span><br><span class="line">            b_initializer = tf.constant_initializer(<span class="number">0.1</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#eval_networkç¬¬ä¸€å±‚å…¨è¿æ¥ç¥ç»ç½‘ç»œ</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;l1&#x27;</span>):</span><br><span class="line">                w1 = tf.get_variable(<span class="string">&#x27;w1&#x27;</span>, [self.n_features, n_l1], initializer=w_initializer, collections=c_names)</span><br><span class="line">                b1 = tf.get_variable(<span class="string">&#x27;b1&#x27;</span>, [<span class="number">1</span>, n_l1], initializer=b_initializer, collections=c_names)</span><br><span class="line">                l1 = tf.nn.relu(tf.matmul(self.s, w1)+b1)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#eval_networkç¬¬äºŒå±‚å…¨è¿æ¥ç¥ç»ç½‘ç»œ</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;l1&#x27;</span>):</span><br><span class="line">                w2 = tf.get_variable(<span class="string">&#x27;w2&#x27;</span>, [n_l1, self.n_actions], initializer=w_initializer, collections=c_names)</span><br><span class="line">                b2 = tf.get_variable(<span class="string">&#x27;b2&#x27;</span>, [<span class="number">1</span>, self.n_actions], initializer=b_initializer, collections=c_names)</span><br><span class="line">                <span class="comment">#æ±‚å‡ºqä¼°è®¡å€¼ï¼Œé•¿åº¦ä¸ºn_actionsçš„å‘é‡</span></span><br><span class="line">                self.q_eval = tf.matmul(l1, w2) + b2</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;loss&#x27;</span>): <span class="comment"># æ±‚è¯¯å·®</span></span><br><span class="line">            <span class="comment">#ä½¿ç”¨å¹³æ–¹è¯¯å·®</span></span><br><span class="line">            self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_eval))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;train&#x27;</span>):    <span class="comment"># æ¢¯åº¦ä¸‹é™</span></span><br><span class="line">            optimizer = tf.train.RMSPropOptimizer(self.lr)</span><br><span class="line">            self._train_op = optimizer.minimize(self.loss)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#åˆ›å»ºtarget networkï¼Œè¾“å…¥é€‰æ‹©ä¸€ä¸ªactionåçš„çŠ¶æ€s_,è¾“å‡ºq_target</span></span><br><span class="line">        self.s_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, self.n_features], name=<span class="string">&#x27;s_&#x27;</span>)    <span class="comment"># æ¥æ”¶ä¸‹ä¸ª observation</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;target_net&#x27;</span>):</span><br><span class="line">            c_names = [<span class="string">&#x27;target_net_params&#x27;</span>, tf.GraphKeys.GLOBAL_VARIABLES]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># target_net çš„ç¬¬ä¸€å±‚fcï¼Œ collections æ˜¯åœ¨æ›´æ–° target_net å‚æ•°æ—¶ä¼šç”¨åˆ°</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;l1&#x27;</span>):</span><br><span class="line">                w1 = tf.get_variable(<span class="string">&#x27;w1&#x27;</span>, [self.n_features, n_l1], initializer=w_initializer, collections=c_names)</span><br><span class="line">                b1 = tf.get_variable(<span class="string">&#x27;b1&#x27;</span>, [<span class="number">1</span>, n_l1], initializer=b_initializer, collections=c_names)</span><br><span class="line">                l1 = tf.nn.relu(tf.matmul(self.s_, w1) + b1)</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># target_net çš„ç¬¬äºŒå±‚fc</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;l2&#x27;</span>):</span><br><span class="line">                w2 = tf.get_variable(<span class="string">&#x27;w2&#x27;</span>, [n_l1, self.n_actions], initializer=w_initializer, collections=c_names)</span><br><span class="line">                b2 = tf.get_variable(<span class="string">&#x27;b2&#x27;</span>, [<span class="number">1</span>, self.n_actions], initializer=b_initializer, collections=c_names)</span><br><span class="line">                <span class="comment">#ç”³è¯·ç½‘ç»œè¾“å‡º</span></span><br><span class="line">                self.q_next = tf.matmul(l1, w2) + b2</span><br><span class="line">            </span><br><span class="line">        <span class="built_in">print</span>(self.q_next)</span><br><span class="line">                </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">choose_action</span>(<span class="params">self, observation</span>):</span><br><span class="line">        <span class="comment">#æ ¹æ®observationï¼ˆstateï¼‰é€‰è¡Œä¸º</span></span><br><span class="line">        <span class="comment">#ä½¿ç”¨eval networké€‰å‡ºstateä¸‹çš„è¡Œä¸ºä¼°è®¡</span></span><br><span class="line">        <span class="comment">#å°†observationçš„shapeå˜ä¸º(1, size_of_observation)ï¼Œè¡Œå‘é‡å˜ä¸ºåˆ—å‘é‡æ‰èƒ½ä¸NNç»´åº¦ç»Ÿä¸€</span></span><br><span class="line">        observation = observation[np.newaxis, :]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> np.random.uniform() &lt; self.epsilon:</span><br><span class="line">            action_value = self.sess.run(self.q_eval, feed_dict=&#123;self.s:observation&#125;)</span><br><span class="line">            action = np.argmax(action_value)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            action = np.random.randint(<span class="number">0</span>, self.n_actions)   <span class="comment">#éšæœºé€‰æ‹©</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">learn</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> self.learn_step_counter % self.replace_target_iter ==<span class="number">0</span>:</span><br><span class="line">            self.sess.run(self.replace_target_op)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;\ntarget_params_replaced\n&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#ä»memoryä¸­éšæœºæŠ½å–batch_sizeè¿™ä¹ˆå¤šè®°å¿†</span></span><br><span class="line">        <span class="keyword">if</span> self.memory_counter &gt; self.memory_size:   <span class="comment">#è¯´æ˜è®°å¿†åº“å·²ç»å­˜æ»¡ï¼Œå¯ä»¥ä»è®°å¿†åº“ä»»æ„ä½ç½®æ”¶å–</span></span><br><span class="line">            sample_index = np.random.choice(self.memory_size, size=self.batch_size)</span><br><span class="line">        <span class="keyword">else</span>:   <span class="comment">#è®°å¿†åº“è¿˜æ²¡æœ‰å­˜æ»¡ï¼Œä»ç°æœ‰çš„å­˜å‚¨è®°å¿†æå–</span></span><br><span class="line">            sample_index = np.random.choice(self.memory_counter, size=self.batch_size)</span><br><span class="line">        </span><br><span class="line">        batch_memory= self.memory[sample_index, :]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># è·å–q_nextå³qç°å®(target_netäº§ç”Ÿçš„q)å’Œq_eval(eval_netäº§ç”Ÿçš„q)</span></span><br><span class="line">        <span class="comment">#q_nextå’Œq_evaléƒ½æ˜¯ä¸€ä¸ªå‘é‡ï¼ŒåŒ…å«äº†å¯¹åº”çŠ¶æ€ä¸‹æ‰€æœ‰åŠ¨ä½œçš„qå€¼</span></span><br><span class="line">        <span class="comment">#å®é™…ä¸Šfeatureä¸ºçŠ¶æ€çš„ç»´åº¦ï¼Œbatch_memory[:, -self.n_features:]ä¸ºs_,å³çŠ¶æ€sé‡‡å–åŠ¨ä½œactionåçš„çŠ¶æ€s_, batch_memory[:, :self.n_features]ä¸ºs</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># è·å–q_nextå³qç°å®(target_netäº§ç”Ÿçš„q)å’Œq_eval(eval_netäº§ç”Ÿçš„q)</span></span><br><span class="line">        <span class="comment">#q_nextå’Œq_evaléƒ½æ˜¯ä¸€ä¸ªå‘é‡ï¼ŒåŒ…å«äº†å¯¹åº”çŠ¶æ€ä¸‹æ‰€æœ‰åŠ¨ä½œçš„qå€¼</span></span><br><span class="line">        <span class="comment">#å®é™…ä¸Šfeatureä¸ºçŠ¶æ€çš„ç»´åº¦ï¼Œbatch_memory[:, -self.n_features:]ä¸ºs_,å³çŠ¶æ€sé‡‡å–åŠ¨ä½œactionåçš„çŠ¶æ€s_, batch_memory[:, :self.n_features]ä¸ºs</span></span><br><span class="line">        <span class="comment">#q_next, q_evalçš„ç»´åº¦ä¸º[None,n_actions]</span></span><br><span class="line">        q_next, q_eval = self.sess.run([self.q_next, self.q_eval], feed_dict=&#123;self.s_: batch_memory[:, -self.n_features:],self.s: batch_memory[:, :self.n_features]&#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#ç”¨t+1çš„çŠ¶æ€å¸¦å…¥eval networkå…ˆé€‰å‡ºåŠ¨ä½œ</span></span><br><span class="line">        action_value = self.sess.run(self.q_eval, feed_dict=&#123;self.s: batch_memory[:, -self.n_features:]&#125;)</span><br><span class="line">        <span class="comment">#ç»´åº¦ä¸º[batch_size, 1]</span></span><br><span class="line">        action = np.argmax(action_value, axis=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#ä¸‹é¢è¿™å‡ æ­¥ååˆ†é‡è¦. q_next, q_eval åŒ…å«æ‰€æœ‰ action çš„å€¼, è€Œæˆ‘ä»¬éœ€è¦çš„åªæ˜¯å·²ç»é€‰æ‹©å¥½çš„ action çš„å€¼, å…¶ä»–çš„å¹¶ä¸éœ€è¦.æ‰€ä»¥æˆ‘ä»¬å°†å…¶ä»–çš„ action å€¼å…¨å˜æˆ 0, å°†ç”¨åˆ°çš„ action è¯¯å·®å€¼ åå‘ä¼ é€’å›å», ä½œä¸ºæ›´æ–°å‡­æ®.</span></span><br><span class="line">        <span class="comment">#è¿™æ˜¯æˆ‘ä»¬æœ€ç»ˆè¦è¾¾åˆ°çš„æ ·å­, æ¯”å¦‚ q_target - q_eval = [1, 0, 0] - [-1, 0, 0] = [2, 0, 0]</span></span><br><span class="line">        <span class="comment"># q_eval = [-1, 0, 0] è¡¨ç¤ºè¿™ä¸€ä¸ªè®°å¿†ä¸­æœ‰æˆ‘é€‰ç”¨è¿‡ action 0, è€Œaction0å¸¦æ¥çš„ Q(s, a0)=-1,è€Œå…¶ä»–çš„ Q(s, a1)=Q(s, a2)=0</span></span><br><span class="line">        <span class="comment"># q_target = [1, 0, 0] è¡¨ç¤ºè¿™ä¸ªè®°å¿†ä¸­çš„ r+gamma*maxQ(s_) = 1, è€Œä¸”ä¸ç®¡åœ¨ s_ ä¸Šæˆ‘ä»¬å–äº†å“ªä¸ª action</span></span><br><span class="line">        <span class="comment"># æˆ‘ä»¬éƒ½éœ€è¦å¯¹åº”ä¸Š q_eval ä¸­çš„ action ä½ç½®, æ‰€ä»¥å°±å°† q_targetçš„1æ”¾åœ¨äº† action0çš„ä½ç½®.</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ä¸‹é¢ä¹Ÿæ˜¯ä¸ºäº†è¾¾åˆ°ä¸Šé¢è¯´çš„ç›®çš„, ä¸è¿‡ä¸ºäº†æ›´æ–¹é¢è®©ç¨‹åºè¿ç®—, è¾¾åˆ°ç›®çš„çš„è¿‡ç¨‹æœ‰ç‚¹ä¸åŒ.# æ˜¯å°† q_eval å…¨éƒ¨èµ‹å€¼ç»™ q_target, è¿™æ—¶ q_target-q_eval å…¨ä¸º 0,</span></span><br><span class="line">        <span class="comment"># ä¸è¿‡ æˆ‘ä»¬å†æ ¹æ® batch_memory å½“ä¸­çš„ action è¿™ä¸ª column æ¥ç»™ q_target ä¸­çš„å¯¹åº”çš„ memory-action ä½ç½®æ¥ä¿®æ”¹èµ‹å€¼.</span></span><br><span class="line">        <span class="comment"># ä½¿æ–°çš„èµ‹å€¼ä¸º reward + gamma * maxQ(s_), è¿™æ · q_target-q_eval å°±å¯ä»¥å˜æˆæˆ‘ä»¬æ‰€éœ€çš„æ ·å­.</span></span><br><span class="line">        q_target = q_eval.copy()</span><br><span class="line">        <span class="comment">#æ¯ä¸ªæ ·æœ¬ä¸‹æ ‡</span></span><br><span class="line">        batch_index = np.arange(self.batch_size, dtype=np.int32)</span><br><span class="line">        <span class="comment">#è®°å½•æ¯ä¸ªæ ·æœ¬æ‰§è¡Œçš„åŠ¨ä½œ</span></span><br><span class="line">        eval_act_index = batch_memory[:, self.n_features].astype(<span class="built_in">int</span>)</span><br><span class="line">        <span class="comment">#è®°å½•æ¯ä¸ªæ ·æœ¬åŠ¨ä½œçš„å¥–åŠ±</span></span><br><span class="line">        reward = batch_memory[:, self.n_features + <span class="number">1</span>]</span><br><span class="line">        <span class="comment">#ç”Ÿæˆæ¯ä¸ªæ ·æœ¬ä¸­qå€¼å¯¹åº”åŠ¨ä½œçš„æ›´æ–°ï¼Œå³ç”Ÿæˆçš„qç°å®ï¼Œ </span></span><br><span class="line">        q_target[batch_index, eval_act_index]=reward+self.gamma * q_next[batch_index, action] </span><br><span class="line">        </span><br><span class="line">        <span class="comment">#å‡å¦‚åœ¨è¿™ä¸ª batch ä¸­, æˆ‘ä»¬æœ‰2ä¸ªæå–çš„è®°å¿†, æ ¹æ®æ¯ä¸ªè®°å¿†å¯ä»¥ç”Ÿäº§3ä¸ª action çš„å€¼:</span></span><br><span class="line">        <span class="comment">#q_eval =[[1, 2, 3],[4, 5, 6]]ï¼Œ å¦q_target = q_eval.copy()</span></span><br><span class="line">        <span class="comment">#ç„¶åæ ¹æ® memory å½“ä¸­çš„å…·ä½“ action ä½ç½®æ¥ä¿®æ”¹ q_target å¯¹åº” action ä¸Šçš„å€¼:</span></span><br><span class="line">        <span class="comment">#æ¯”å¦‚åœ¨:è®°å¿† 0 çš„ q_target è®¡ç®—å€¼æ˜¯ -1, è€Œä¸”æˆ‘ç”¨äº† action 0;å¿†1çš„ q_target è®¡ç®—å€¼æ˜¯-2, è€Œä¸”æˆ‘ç”¨äº† action 2:</span></span><br><span class="line">        <span class="comment">#q_target =[[-1, 2, 3],[4, 5, -2]]</span></span><br><span class="line">        <span class="comment">#æ‰€ä»¥ (q_target - q_eval) å°±å˜æˆäº†:[[(-1)-(1), 0, 0],[0, 0, (-2)-(6)]]</span></span><br><span class="line">        <span class="comment">#æœ€åæˆ‘ä»¬å°†è¿™ä¸ª (q_target - q_eval) å½“æˆè¯¯å·®, åå‘ä¼ é€’ä¼šç¥ç»ç½‘ç»œ</span></span><br><span class="line">        <span class="comment">#æ‰€æœ‰ä¸º 0 çš„ action å€¼æ˜¯å½“æ—¶æ²¡æœ‰é€‰æ‹©çš„ action, ä¹‹å‰æœ‰é€‰æ‹©çš„ action æ‰æœ‰ä¸ä¸º0çš„å€¼.</span></span><br><span class="line">        <span class="comment">#æˆ‘ä»¬åªåå‘ä¼ é€’ä¹‹å‰é€‰æ‹©çš„ action çš„å€¼,</span></span><br><span class="line">        _, self.cost = self.sess.run([self._train_op, self.loss],feed_dict=&#123;self.s: batch_memory[:, :self.n_features],self.q_target: q_target&#125;)</span><br><span class="line">        </span><br><span class="line">        self.cost_his.append(self.cost) <span class="comment"># è®°å½• cost è¯¯å·®</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#æ¯è°ƒç”¨ä¸€æ¬¡learnï¼Œé™ä½ä¸€æ¬¡epsilonï¼Œå³è¡Œä¸ºéšæœºæ€§</span></span><br><span class="line">        self.epsilon = self.epsilon + self.epsilon_increment <span class="keyword">if</span> self.epsilon &lt; self.epsilon_max <span class="keyword">else</span> self.epsilon_max</span><br><span class="line">        </span><br><span class="line">        self.learn_step_counter += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">plot_cost</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">        plt.plot(np.arange(<span class="built_in">len</span>(self.cost_his)), self.cost_his)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;Cost&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;training steps&#x27;</span>)</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure>



<p>Double-DQNçš„agentç¼–å†™ä¸DQNå‡ ä¹ä¸€æ ·åªæ˜¯åœ¨æ±‚qä¼°è®¡çš„æ—¶å€™å…ˆç”¨eval networkæ±‚å‡ºä»·å€¼æœ€å¤§çš„åŠ¨ä½œï¼Œå†è®²è¿™ä¸ªåŠ¨ä½œå¸¦å…¥target networkã€‚<br>ä¹‹å‰åœ¨DQNä¸­ä½¿ç”¨çš„å…¬å¼ä¸º</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">q_target[batch_index, eval_act_index]=reward+self.gamma * np.<span class="built_in">max</span>(q_next, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#æ”¹ä¸ºï¼š</span></span><br><span class="line"><span class="comment">#ç”¨t+1çš„çŠ¶æ€å¸¦å…¥eval networkå…ˆé€‰å‡ºåŠ¨ä½œ</span></span><br><span class="line">action_value = self.sess.run(self.q_eval, feed_dict=&#123;self.s: batch_memory[:, -self.n_features:]&#125;)</span><br><span class="line"><span class="comment">#ç»´åº¦ä¸º[batch_size, 1]</span></span><br><span class="line">action = np.argmax(action_value, axis=<span class="number">1</span>)</span><br><span class="line">q_target[batch_index, eval_act_index]=reward+self.gamma * q_next[batch_index, action]</span><br></pre></td></tr></table></figure>



<h4 id="Duling-DQN"><a href="#Duling-DQN" class="headerlink" title="Duling DQN"></a>Duling DQN</h4><p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316204901396.png" alt="image-20210316204901396"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316204930844.png" alt="image-20210316204930844"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316205031940.png" alt="image-20210316205031940"></p>
<p>Dueling DQNä¸DQNçš„ç½‘ç»œç»“æ„ä¸åŒï¼Œå…¶ä»–è¿‡ç¨‹ç›¸ä¼¼ã€‚ç€é‡æ˜¯æ›´æ”¹åŸæ¥DQN Agentçš„build_net()æ–¹æ³•ã€‚<br>ä¹‹å‰æ„å»ºçš„æ–¹å¼æ˜¯é€šè¿‡ä¸€ä¸ªéšè—å±‚ç›´æ¥è·å¾—qå€¼</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;l1&#x27;</span>):</span><br><span class="line">                w2 = tf.get_variable(<span class="string">&#x27;w2&#x27;</span>, [n_l1, self.n_actions], initializer=w_initializer, collections=c_names)</span><br><span class="line">                b2 = tf.get_variable(<span class="string">&#x27;b2&#x27;</span>, [<span class="number">1</span>, self.n_actions], initializer=b_initializer, collections=c_names)</span><br><span class="line">                <span class="comment">#æ±‚å‡ºqä¼°è®¡å€¼ï¼Œé•¿åº¦ä¸ºn_actionsçš„å‘é‡</span></span><br><span class="line">                self.q_eval = tf.matmul(l1, w2) + b2</span><br><span class="line">                </span><br><span class="line"><span class="comment">#ç°åœ¨å°†q_eval æ‹†åˆ†ä¸ºçŠ¶æ€ä»·å€¼vå’ŒåŠ¨ä½œä»·å€¼aï¼Œå…¶ä¸­åŠ¨ä½œä»·å€¼açš„å‡å€¼ä¸º0ï¼ˆq_targetéœ€è¦åšåŒæ ·çš„æ”¹åŠ¨ï¼‰ï¼š</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#çŠ¶æ€çš„ä»·å€¼</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;value&#x27;</span>):</span><br><span class="line">                w21 = tf.get_variable(<span class="string">&#x27;w21&#x27;</span>, [n_l1, <span class="number">1</span>], initializer=w_initializer, collections=c_names)</span><br><span class="line">                b21 = tf.get_variable(<span class="string">&#x27;b21&#x27;</span>, [<span class="number">1</span>], initializer=b_initializer, collections=c_names)</span><br><span class="line">                vs_out = tf.matmul(l1, w21) + b21</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#åŠ¨ä½œçš„advantage</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;advantage&#x27;</span>):</span><br><span class="line">                w22 = tf.get_variable(<span class="string">&#x27;w22&#x27;</span>, [n_l1, self.n_actions], initializer=w_initializer, collections=c_names)</span><br><span class="line">                b22 = tf.get_variable(<span class="string">&#x27;b22&#x27;</span>, [<span class="number">1</span>, self.n_actions], initializer=b_initializer, collections=c_names)</span><br><span class="line">                aa = tf.matmul(l1, w22) + b22</span><br><span class="line">                <span class="comment">#ä¸ºäº†ä¸è®©Aç›´æ¥å­¦æˆäº†Q, æˆ‘ä»¬å‡æ‰äº†Açš„å‡å€¼ï¼Œæ­¤æ—¶Açš„å‡å€¼å§‹ç»ˆä¸º0</span></span><br><span class="line">                aa_out = aa - tf.reduce_mean(aa, axis=<span class="number">1</span>, keep_dims=<span class="literal">True</span>)</span><br><span class="line">                </span><br><span class="line">            <span class="comment">#åˆå¹¶Vå’ŒA, æ±‚å‡ºqä¼°è®¡å€¼</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;Q&#x27;</span>):</span><br><span class="line">                self.q_eval = vs_out + aa_out</span><br><span class="line">                </span><br><span class="line">               </span><br></pre></td></tr></table></figure>

<p>å®Œæ•´çš„dueling DQNçš„Agentçš„ä»£ç å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Dueling_DeepQNetwork</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="comment">#replace_target_iterä¸ºæ›´æ–°target networkçš„æ­¥æ•°ï¼Œé˜²æ­¢target networkå’Œeval networkå·®åˆ«è¿‡å¤§</span></span><br><span class="line">    <span class="comment">#memory_sizeä¸ºbufferå‚¨å­˜è®°å¿†ä¸Šçº¿ï¼Œæ–¹ä¾¿ä½¿ç”¨ä»¥å‰è®°å¿†å­¦ä¹ </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_actions, n_features,learning_rate=<span class="number">0.01</span>,reward_decay=<span class="number">0.9</span>,e_greedy=<span class="number">0.9</span>,replace_target_iter=<span class="number">300</span>,memory_size=<span class="number">500</span>,batch_size=<span class="number">32</span>,e_greedy_increment=<span class="literal">None</span>,output_graph=<span class="literal">False</span></span>):</span><br><span class="line">        self.n_actions = n_actions</span><br><span class="line">        self.n_features = n_features</span><br><span class="line">        self.lr = learning_rate</span><br><span class="line">        self.gamma = reward_decay</span><br><span class="line">        self.epsilon_max = e_greedy     <span class="comment"># epsilonåé¢å¥–åŠ±å¯¹å‰é¢çš„é€’å‡å‚æ•°</span></span><br><span class="line">        self.replace_target_iter = replace_target_iter  <span class="comment"># æ›´æ¢ target_net çš„æ­¥æ•°</span></span><br><span class="line">        self.memory_size = memory_size  <span class="comment"># è®°å¿†ä¸Šé™</span></span><br><span class="line">        self.batch_size = batch_size    <span class="comment"># æ¯æ¬¡æ›´æ–°æ—¶ä» memory é‡Œé¢å–å¤šå°‘è®°å¿†å‡ºæ¥</span></span><br><span class="line">        self.epsilon_increment = e_greedy_increment <span class="comment"># epsilon çš„å¢é‡</span></span><br><span class="line">        <span class="comment">#epsilon = 0ç­‰äº0æ—¶ï¼Œåé¢çš„å¥–åŠ±åˆ›ä¼ ä¸åˆ°å‰é¢ï¼Œå‰é¢çš„çŠ¶æ€å°±å¼€å¯éšæœºæ¢ç´¢æ¨¡å¼</span></span><br><span class="line">        self.epsilon = <span class="number">0</span> <span class="keyword">if</span> e_greedy_increment <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> self.epsilon_max <span class="comment"># æ˜¯å¦å¼€å¯æ¢ç´¢æ¨¡å¼, å¹¶é€æ­¥å‡å°‘æ¢ç´¢æ¬¡æ•°</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># è®°å½•å­¦ä¹ æ¬¡æ•° (ç”¨äºåˆ¤æ–­æ˜¯å¦æ›´æ¢ target_net å‚æ•°)</span></span><br><span class="line">        self.learn_step_counter = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># åˆå§‹åŒ–å…¨ 0 è®°å¿† [s, a, r, s_]ï¼Œ å®é™…ä¸Šfeatureä¸ºçŠ¶æ€çš„ç»´åº¦ï¼Œn_features*2åˆ†åˆ«è®°å½•så’Œs_ï¼Œ+2è®°å½•aå’Œr</span></span><br><span class="line">        self.memory = np.zeros((self.memory_size, n_features*<span class="number">2</span>+<span class="number">2</span>))</span><br><span class="line">        </span><br><span class="line">        self._build_net()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#æ›¿æ¢ target net çš„å‚æ•°</span></span><br><span class="line">        t_params = tf.get_collection(<span class="string">&#x27;target_net_params&#x27;</span>)  <span class="comment">#æå– target_net çš„å‚æ•°</span></span><br><span class="line">        e_params = tf.get_collection(<span class="string">&#x27;eval_net_params&#x27;</span>)   <span class="comment"># æå–  eval_net çš„å‚æ•°</span></span><br><span class="line">        <span class="comment">#å°†eval_networkä¸­æ¯ä¸€ä¸ªvariableçš„å€¼èµ‹å€¼ç»™target networkçš„å¯¹åº”å˜é‡</span></span><br><span class="line">        self.replace_target_op = [tf.assign(t, e) <span class="keyword">for</span> t, e <span class="keyword">in</span> <span class="built_in">zip</span>(t_params, e_params)] <span class="comment">#æ›´æ–° target_net å‚æ•°</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        self.sess = tf.Session()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> output_graph:</span><br><span class="line">            tf.summary.FileWriter(<span class="string">&quot;logs/&quot;</span>, self.sess.graph)</span><br><span class="line">        </span><br><span class="line">        self.sess.run(tf.global_variables_initializer())</span><br><span class="line">        <span class="comment">#ç”¨äºè®°å½•# è®°å½•æ‰€æœ‰ cost å˜åŒ–</span></span><br><span class="line">        self.cost_his = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#æå®æ¯…è€å¸ˆå…‹é‡çš„relpay bufferï¼Œé€šè¿‡ä»¥å¾€çš„è®°å¿†ä¸­ä¸æ–­è®­ç»ƒ</span></span><br><span class="line">    <span class="comment">#è¿™æ˜¯DQNå˜ä¸ºoff-policyçš„æ ¸å¿ƒ</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">store_transition</span>(<span class="params">self, s, a, r, s_</span>):</span><br><span class="line">        <span class="comment">#å¦‚æœDeepQNetworkä¸­å®šä¹‰äº†memory_counterï¼Œè¿›è¡Œè®°å¿†å­˜å‚¨</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(self, <span class="string">&#x27;memory_counter&#x27;</span>):</span><br><span class="line">            self.memory_counter = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#è®°å½•ä¸€æ¡ [s, a, r, s_] è®°å½•</span></span><br><span class="line">        transition = np.hstack((s, [a, r], s_))</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#æ€» memory å¤§å°æ˜¯å›ºå®šçš„, å¦‚æœè¶…å‡ºæ€»å¤§å°, æ—§ memory å°±è¢«æ–° memory æ›¿æ¢</span></span><br><span class="line">        index = self.memory_counter % self.memory_size  <span class="comment">#ç±»ä¼¼hashmapèµ‹å€¼æ€æƒ³</span></span><br><span class="line">        self.memory[index, :] = transition  <span class="comment">#è¿›è¡Œæ›¿æ¢</span></span><br><span class="line">        </span><br><span class="line">        self.memory_counter += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment">#å»ºç«‹ç¥ç»ç½‘ç»œ</span></span><br><span class="line">    <span class="comment">#æ­¤å¤„å»ºç«‹ä¸¤ä¸ªç”³è¯·ç½‘ç»œï¼Œä¸€ä¸ªä¸ºtarget networkï¼Œç”¨äºå¾—åˆ°qç°å®ã€‚ä¸€ä¸ªä¸ºeval_networkï¼Œç”¨äºå¾—åˆ°qä¼°è®¡</span></span><br><span class="line">    <span class="comment">#target networkå’Œeval_networkç»“æ„ä¸€æ ·ï¼Œtarget networkç”¨æ¯”è¾ƒè€çš„å‚æ•°ï¼Œeval_networkä¸ºçœŸæ­£è®­ç»ƒçš„ç¥ç»ç½‘ç»œ</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_net</span>(<span class="params">self</span>):</span><br><span class="line">        tf.reset_default_graph()  <span class="comment">#æ¸…ç©ºè®¡ç®—å›¾</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#åˆ›å»ºevalç¥ç»ç½‘ç»œ,åŠæ—¶æå‡å‚æ•°</span></span><br><span class="line">        self.s = tf.placeholder(tf.float32, [<span class="literal">None</span>, self.n_features], name=<span class="string">&#x27;s&#x27;</span>)  <span class="comment"># ç”¨æ¥æ¥æ”¶ observationï¼Œå³ç¥ç»ç½‘ç»œçš„è¾“å…¥</span></span><br><span class="line">        self.q_target = tf.placeholder(tf.float32, [<span class="literal">None</span>, self.n_actions], name=<span class="string">&#x27;Q_target&#x27;</span>) <span class="comment"># q_targetçš„å€¼, è¿™ä¸ªä¹‹åä¼šé€šè¿‡è®¡ç®—å¾—åˆ°ï¼Œç¥ç»ç½‘ç»œçš„è¾“å‡º</span></span><br><span class="line">        <span class="comment">#eval_netåŸŸä¸‹çš„å˜é‡</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;eval_net&#x27;</span>):</span><br><span class="line">            <span class="comment">#c_namesç”¨äºåœ¨ä¸€å®šæ­¥æ•°ä¹‹åæ›´æ–°target network</span></span><br><span class="line">            <span class="comment">#GLOBAL_VARIABLESä½œç”¨æ˜¯collectioné»˜è®¤åŠ å…¥æ‰€æœ‰çš„Variableå¯¹è±¡ï¼Œç”¨äºå…±äº«</span></span><br><span class="line">            c_names = [<span class="string">&#x27;eval_net_params&#x27;</span>, tf.GraphKeys.GLOBAL_VARIABLES]</span><br><span class="line">            n_l1 = <span class="number">10</span>  <span class="comment">#n_l1ä¸ºnetworkéšè—å±‚ç¥ç»å…ƒçš„ä¸ªæ•° </span></span><br><span class="line">            w_initializer = tf.random_normal_initializer(<span class="number">0.</span>,<span class="number">0.3</span>)  </span><br><span class="line">            b_initializer = tf.constant_initializer(<span class="number">0.1</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#eval_networkç¬¬ä¸€å±‚å…¨è¿æ¥ç¥ç»ç½‘ç»œ</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;l1&#x27;</span>):</span><br><span class="line">                w1 = tf.get_variable(<span class="string">&#x27;w1&#x27;</span>, [self.n_features, n_l1], initializer=w_initializer, collections=c_names)</span><br><span class="line">                b1 = tf.get_variable(<span class="string">&#x27;b1&#x27;</span>, [<span class="number">1</span>, n_l1], initializer=b_initializer, collections=c_names)</span><br><span class="line">                l1 = tf.nn.relu(tf.matmul(self.s, w1)+b1)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#çŠ¶æ€çš„ä»·å€¼</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;value&#x27;</span>):</span><br><span class="line">                w21 = tf.get_variable(<span class="string">&#x27;w21&#x27;</span>, [n_l1, <span class="number">1</span>], initializer=w_initializer, collections=c_names)</span><br><span class="line">                b21 = tf.get_variable(<span class="string">&#x27;b21&#x27;</span>, [<span class="number">1</span>], initializer=b_initializer, collections=c_names)</span><br><span class="line">                vs_out = tf.matmul(l1, w21) + b21</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#åŠ¨ä½œçš„advantage</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;advantage&#x27;</span>):</span><br><span class="line">                w22 = tf.get_variable(<span class="string">&#x27;w22&#x27;</span>, [n_l1, self.n_actions], initializer=w_initializer, collections=c_names)</span><br><span class="line">                b22 = tf.get_variable(<span class="string">&#x27;b22&#x27;</span>, [<span class="number">1</span>, self.n_actions], initializer=b_initializer, collections=c_names)</span><br><span class="line">                aa = tf.matmul(l1, w22) + b22</span><br><span class="line">                <span class="comment">#ä¸ºäº†ä¸è®©Aç›´æ¥å­¦æˆäº†Q, æˆ‘ä»¬å‡æ‰äº†Açš„å‡å€¼ï¼Œæ­¤æ—¶Açš„å‡å€¼å§‹ç»ˆä¸º0</span></span><br><span class="line">                aa_out = aa - tf.reduce_mean(aa, axis=<span class="number">1</span>, keep_dims=<span class="literal">True</span>)</span><br><span class="line">                </span><br><span class="line">            <span class="comment">#åˆå¹¶Vå’ŒA, æ±‚å‡ºqä¼°è®¡å€¼</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;Q&#x27;</span>):</span><br><span class="line">                self.q_eval = vs_out + aa_out</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;loss&#x27;</span>): <span class="comment"># æ±‚è¯¯å·®</span></span><br><span class="line">            <span class="comment">#ä½¿ç”¨å¹³æ–¹è¯¯å·®</span></span><br><span class="line">            self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_eval))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;train&#x27;</span>):    <span class="comment"># æ¢¯åº¦ä¸‹é™</span></span><br><span class="line">            optimizer = tf.train.RMSPropOptimizer(self.lr)</span><br><span class="line">            self._train_op = optimizer.minimize(self.loss)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#åˆ›å»ºtarget networkï¼Œè¾“å…¥é€‰æ‹©ä¸€ä¸ªactionåçš„çŠ¶æ€s_,è¾“å‡ºq_target</span></span><br><span class="line">        self.s_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, self.n_features], name=<span class="string">&#x27;s_&#x27;</span>)    <span class="comment"># æ¥æ”¶ä¸‹ä¸ª observation</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;target_net&#x27;</span>):</span><br><span class="line">            c_names = [<span class="string">&#x27;target_net_params&#x27;</span>, tf.GraphKeys.GLOBAL_VARIABLES]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># target_net çš„ç¬¬ä¸€å±‚fcï¼Œ collections æ˜¯åœ¨æ›´æ–° target_net å‚æ•°æ—¶ä¼šç”¨åˆ°</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;l1&#x27;</span>):</span><br><span class="line">                w1 = tf.get_variable(<span class="string">&#x27;w1&#x27;</span>, [self.n_features, n_l1], initializer=w_initializer, collections=c_names)</span><br><span class="line">                b1 = tf.get_variable(<span class="string">&#x27;b1&#x27;</span>, [<span class="number">1</span>, n_l1], initializer=b_initializer, collections=c_names)</span><br><span class="line">                l1 = tf.nn.relu(tf.matmul(self.s_, w1) + b1)</span><br><span class="line"></span><br><span class="line">            <span class="comment">#çŠ¶æ€çš„ä»·å€¼</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;value&#x27;</span>):</span><br><span class="line">                w21 = tf.get_variable(<span class="string">&#x27;w21&#x27;</span>, [n_l1, <span class="number">1</span>], initializer=w_initializer, collections=c_names)</span><br><span class="line">                b21 = tf.get_variable(<span class="string">&#x27;b21&#x27;</span>, [<span class="number">1</span>], initializer=b_initializer, collections=c_names)</span><br><span class="line">                vs_out = tf.matmul(l1, w21) + b21</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#åŠ¨ä½œçš„advantage</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;advantage&#x27;</span>):</span><br><span class="line">                w22 = tf.get_variable(<span class="string">&#x27;w22&#x27;</span>, [n_l1, self.n_actions], initializer=w_initializer, collections=c_names)</span><br><span class="line">                b22 = tf.get_variable(<span class="string">&#x27;b22&#x27;</span>, [<span class="number">1</span>, self.n_actions], initializer=b_initializer, collections=c_names)</span><br><span class="line">                aa = tf.matmul(l1, w22) + b22</span><br><span class="line">                <span class="comment">#ä¸ºäº†ä¸è®©Aç›´æ¥å­¦æˆäº†Q, æˆ‘ä»¬å‡æ‰äº†Açš„å‡å€¼ï¼Œæ­¤æ—¶Açš„å‡å€¼å§‹ç»ˆä¸º0</span></span><br><span class="line">                aa_out = aa - tf.reduce_mean(aa, axis=<span class="number">1</span>, keep_dims=<span class="literal">True</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#åˆå¹¶Vå’ŒA, æ±‚å‡ºqä¼°è®¡å€¼</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;Q&#x27;</span>):</span><br><span class="line">                self.q_next = vs_out + aa_out</span><br><span class="line">            </span><br><span class="line">        <span class="built_in">print</span>(self.q_next)</span><br><span class="line">                </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">choose_action</span>(<span class="params">self, observation</span>):</span><br><span class="line">        <span class="comment">#æ ¹æ®observationï¼ˆstateï¼‰é€‰è¡Œä¸º</span></span><br><span class="line">        <span class="comment">#ä½¿ç”¨eval networké€‰å‡ºstateä¸‹çš„è¡Œä¸ºä¼°è®¡</span></span><br><span class="line">        <span class="comment">#å°†observationçš„shapeå˜ä¸º(1, size_of_observation)ï¼Œè¡Œå‘é‡å˜ä¸ºåˆ—å‘é‡æ‰èƒ½ä¸NNç»´åº¦ç»Ÿä¸€</span></span><br><span class="line">        observation = observation[np.newaxis, :]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> np.random.uniform() &lt; self.epsilon:</span><br><span class="line">            action_value = self.sess.run(self.q_eval, feed_dict=&#123;self.s:observation&#125;)</span><br><span class="line">            action = np.argmax(action_value)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            action = np.random.randint(<span class="number">0</span>, self.n_actions)   <span class="comment">#éšæœºé€‰æ‹©</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">learn</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> self.learn_step_counter % self.replace_target_iter ==<span class="number">0</span>:</span><br><span class="line">            self.sess.run(self.replace_target_op)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;\ntarget_params_replaced\n&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#ä»memoryä¸­éšæœºæŠ½å–batch_sizeè¿™ä¹ˆå¤šè®°å¿†</span></span><br><span class="line">        <span class="keyword">if</span> self.memory_counter &gt; self.memory_size:   <span class="comment">#è¯´æ˜è®°å¿†åº“å·²ç»å­˜æ»¡ï¼Œå¯ä»¥ä»è®°å¿†åº“ä»»æ„ä½ç½®æ”¶å–</span></span><br><span class="line">            sample_index = np.random.choice(self.memory_size, size=self.batch_size)</span><br><span class="line">        <span class="keyword">else</span>:   <span class="comment">#è®°å¿†åº“è¿˜æ²¡æœ‰å­˜æ»¡ï¼Œä»ç°æœ‰çš„å­˜å‚¨è®°å¿†æå–</span></span><br><span class="line">            sample_index = np.random.choice(self.memory_counter, size=self.batch_size)</span><br><span class="line">        </span><br><span class="line">        batch_memory= self.memory[sample_index, :]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># è·å–q_nextå³qç°å®(target_netäº§ç”Ÿçš„q)å’Œq_eval(eval_netäº§ç”Ÿçš„q)</span></span><br><span class="line">        <span class="comment">#q_nextå’Œq_evaléƒ½æ˜¯ä¸€ä¸ªå‘é‡ï¼ŒåŒ…å«äº†å¯¹åº”çŠ¶æ€ä¸‹æ‰€æœ‰åŠ¨ä½œçš„qå€¼</span></span><br><span class="line">        <span class="comment">#å®é™…ä¸Šfeatureä¸ºçŠ¶æ€çš„ç»´åº¦ï¼Œbatch_memory[:, -self.n_features:]ä¸ºs_,å³çŠ¶æ€sé‡‡å–åŠ¨ä½œactionåçš„çŠ¶æ€s_, batch_memory[:, :self.n_features]ä¸ºs</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># è·å–q_nextå³qç°å®(target_netäº§ç”Ÿçš„q)å’Œq_eval(eval_netäº§ç”Ÿçš„q)</span></span><br><span class="line">        <span class="comment">#q_nextå’Œq_evaléƒ½æ˜¯ä¸€ä¸ªå‘é‡ï¼ŒåŒ…å«äº†å¯¹åº”çŠ¶æ€ä¸‹æ‰€æœ‰åŠ¨ä½œçš„qå€¼</span></span><br><span class="line">        <span class="comment">#å®é™…ä¸Šfeatureä¸ºçŠ¶æ€çš„ç»´åº¦ï¼Œbatch_memory[:, -self.n_features:]ä¸ºs_,å³çŠ¶æ€sé‡‡å–åŠ¨ä½œactionåçš„çŠ¶æ€s_, batch_memory[:, :self.n_features]ä¸ºs</span></span><br><span class="line">        <span class="comment">#q_next, q_evalçš„ç»´åº¦ä¸º[None,n_actions]</span></span><br><span class="line">        q_next, q_eval = self.sess.run([self.q_next, self.q_eval], feed_dict=&#123;self.s_: batch_memory[:, -self.n_features:],self.s: batch_memory[:, :self.n_features]&#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#ä¸‹é¢è¿™å‡ æ­¥ååˆ†é‡è¦. q_next, q_eval åŒ…å«æ‰€æœ‰ action çš„å€¼, è€Œæˆ‘ä»¬éœ€è¦çš„åªæ˜¯å·²ç»é€‰æ‹©å¥½çš„ action çš„å€¼, å…¶ä»–çš„å¹¶ä¸éœ€è¦.æ‰€ä»¥æˆ‘ä»¬å°†å…¶ä»–çš„ action å€¼å…¨å˜æˆ 0, å°†ç”¨åˆ°çš„ action è¯¯å·®å€¼ åå‘ä¼ é€’å›å», ä½œä¸ºæ›´æ–°å‡­æ®.</span></span><br><span class="line">        <span class="comment">#è¿™æ˜¯æˆ‘ä»¬æœ€ç»ˆè¦è¾¾åˆ°çš„æ ·å­, æ¯”å¦‚ q_target - q_eval = [1, 0, 0] - [-1, 0, 0] = [2, 0, 0]</span></span><br><span class="line">        <span class="comment"># q_eval = [-1, 0, 0] è¡¨ç¤ºè¿™ä¸€ä¸ªè®°å¿†ä¸­æœ‰æˆ‘é€‰ç”¨è¿‡ action 0, è€Œaction0å¸¦æ¥çš„ Q(s, a0)=-1,è€Œå…¶ä»–çš„ Q(s, a1)=Q(s, a2)=0</span></span><br><span class="line">        <span class="comment"># q_target = [1, 0, 0] è¡¨ç¤ºè¿™ä¸ªè®°å¿†ä¸­çš„ r+gamma*maxQ(s_) = 1, è€Œä¸”ä¸ç®¡åœ¨ s_ ä¸Šæˆ‘ä»¬å–äº†å“ªä¸ª action</span></span><br><span class="line">        <span class="comment"># æˆ‘ä»¬éƒ½éœ€è¦å¯¹åº”ä¸Š q_eval ä¸­çš„ action ä½ç½®, æ‰€ä»¥å°±å°† q_targetçš„1æ”¾åœ¨äº† action0çš„ä½ç½®.</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ä¸‹é¢ä¹Ÿæ˜¯ä¸ºäº†è¾¾åˆ°ä¸Šé¢è¯´çš„ç›®çš„, ä¸è¿‡ä¸ºäº†æ›´æ–¹é¢è®©ç¨‹åºè¿ç®—, è¾¾åˆ°ç›®çš„çš„è¿‡ç¨‹æœ‰ç‚¹ä¸åŒ.# æ˜¯å°† q_eval å…¨éƒ¨èµ‹å€¼ç»™ q_target, è¿™æ—¶ q_target-q_eval å…¨ä¸º 0,</span></span><br><span class="line">        <span class="comment"># ä¸è¿‡ æˆ‘ä»¬å†æ ¹æ® batch_memory å½“ä¸­çš„ action è¿™ä¸ª column æ¥ç»™ q_target ä¸­çš„å¯¹åº”çš„ memory-action ä½ç½®æ¥ä¿®æ”¹èµ‹å€¼.</span></span><br><span class="line">        <span class="comment"># ä½¿æ–°çš„èµ‹å€¼ä¸º reward + gamma * maxQ(s_), è¿™æ · q_target-q_eval å°±å¯ä»¥å˜æˆæˆ‘ä»¬æ‰€éœ€çš„æ ·å­.</span></span><br><span class="line">        </span><br><span class="line">        q_target = q_eval.copy()</span><br><span class="line">        <span class="comment">#æ¯ä¸ªæ ·æœ¬ä¸‹æ ‡</span></span><br><span class="line">        batch_index = np.arange(self.batch_size, dtype=np.int32)</span><br><span class="line">        <span class="comment">#è®°å½•æ¯ä¸ªæ ·æœ¬æ‰§è¡Œçš„åŠ¨ä½œ</span></span><br><span class="line">        eval_act_index = batch_memory[:, self.n_features].astype(<span class="built_in">int</span>)</span><br><span class="line">        <span class="comment">#è®°å½•æ¯ä¸ªæ ·æœ¬åŠ¨ä½œçš„å¥–åŠ±</span></span><br><span class="line">        reward = batch_memory[:, self.n_features + <span class="number">1</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#ç”Ÿæˆæ¯ä¸ªæ ·æœ¬ä¸­qå€¼å¯¹åº”åŠ¨ä½œçš„æ›´æ–°ï¼Œå³ç”Ÿæˆçš„qç°å®ï¼Œ</span></span><br><span class="line">        q_target[batch_index, eval_act_index]=reward+self.gamma * np.<span class="built_in">max</span>(q_next, axis=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#å‡å¦‚åœ¨è¿™ä¸ª batch ä¸­, æˆ‘ä»¬æœ‰2ä¸ªæå–çš„è®°å¿†, æ ¹æ®æ¯ä¸ªè®°å¿†å¯ä»¥ç”Ÿäº§3ä¸ª action çš„å€¼:</span></span><br><span class="line">        <span class="comment">#q_eval =[[1, 2, 3],[4, 5, 6]]ï¼Œ å¦q_target = q_eval.copy()</span></span><br><span class="line">        <span class="comment">#ç„¶åæ ¹æ® memory å½“ä¸­çš„å…·ä½“ action ä½ç½®æ¥ä¿®æ”¹ q_target å¯¹åº” action ä¸Šçš„å€¼:</span></span><br><span class="line">        <span class="comment">#æ¯”å¦‚åœ¨:è®°å¿† 0 çš„ q_target è®¡ç®—å€¼æ˜¯ -1, è€Œä¸”æˆ‘ç”¨äº† action 0;å¿†1çš„ q_target è®¡ç®—å€¼æ˜¯-2, è€Œä¸”æˆ‘ç”¨äº† action 2:</span></span><br><span class="line">        <span class="comment">#q_target =[[-1, 2, 3],[4, 5, -2]]</span></span><br><span class="line">        <span class="comment">#æ‰€ä»¥ (q_target - q_eval) å°±å˜æˆäº†:[[(-1)-(1), 0, 0],[0, 0, (-2)-(6)]]</span></span><br><span class="line">        <span class="comment">#æœ€åæˆ‘ä»¬å°†è¿™ä¸ª (q_target - q_eval) å½“æˆè¯¯å·®, åå‘ä¼ é€’ä¼šç¥ç»ç½‘ç»œ</span></span><br><span class="line">        <span class="comment">#æ‰€æœ‰ä¸º 0 çš„ action å€¼æ˜¯å½“æ—¶æ²¡æœ‰é€‰æ‹©çš„ action, ä¹‹å‰æœ‰é€‰æ‹©çš„ action æ‰æœ‰ä¸ä¸º0çš„å€¼.</span></span><br><span class="line">        <span class="comment">#æˆ‘ä»¬åªåå‘ä¼ é€’ä¹‹å‰é€‰æ‹©çš„ action çš„å€¼,</span></span><br><span class="line">        _, self.cost = self.sess.run([self._train_op, self.loss],feed_dict=&#123;self.s: batch_memory[:, :self.n_features],self.q_target: q_target&#125;)</span><br><span class="line">        </span><br><span class="line">        self.cost_his.append(self.cost) <span class="comment"># è®°å½• cost è¯¯å·®</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#æ¯è°ƒç”¨ä¸€æ¬¡learnï¼Œé™ä½ä¸€æ¬¡epsilonï¼Œå³è¡Œä¸ºéšæœºæ€§</span></span><br><span class="line">        self.epsilon = self.epsilon + self.epsilon_increment <span class="keyword">if</span> self.epsilon &lt; self.epsilon_max <span class="keyword">else</span> self.epsilon_max</span><br><span class="line">        </span><br><span class="line">        self.learn_step_counter += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">plot_cost</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">        plt.plot(np.arange(<span class="built_in">len</span>(self.cost_his)), self.cost_his)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;Cost&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;training steps&#x27;</span>)</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure>



<h4 id="Policy-Gradient"><a href="#Policy-Gradient" class="headerlink" title="Policy Gradient"></a>Policy Gradient</h4><p>ä¹‹å‰è¯´çš„SARSAã€Q-learningã€DQNå­¦ä¹ çš„éƒ½æ˜¯åœ¨çŠ¶æ€sä¸‹åŠ¨ä½œaçš„ä»·å€¼ï¼Œå±äºvalue-basedçš„æ–¹æ³•ã€‚è€ŒPolicy Gradientå­¦ä¹ çš„æ˜¯åœ¨çŠ¶æ€sä¸‹æ¯ä¸ªåŠ¨ä½œaè¢«é€‰æ‹©çš„æ¦‚ç‡ï¼Œå±äºpolicy-basedçš„æ–¹æ³•ã€‚</p>
<p>æˆ‘ä»¬å…ˆè¯´Policy Gradientçš„æ•´ä½“æ€æƒ³ï¼Œä¹‹åå°†æ•´ä½“æ€æƒ³è¿›è¡Œæ‹†åˆ†ï¼Œäº§ç”ŸPolicy Gradientæ¯ä¸€æ­¥çš„æµç¨‹ã€‚</p>
<p>Policy Gradientçš„ç½‘ç»œè¦å­¦ä¹ çš„æ˜¯çŠ¶æ€ä¸‹åŠ¨ä½œè¾“å‡ºçš„æ¦‚ç‡ã€‚æŒ‰ç…§å¸¸è¯†æ¥è®²ï¼Œå¯ä»¥è·å¾—è¶Šå¤§çš„å¥–åŠ±çš„åŠ¨ä½œåº”è¯¥è¢«é€‰æ‹©çš„æ¦‚ç‡æ˜¯è¶Šå¤§çš„ã€‚éœ€è¦æ³¨æ„çš„æ˜¯è¿™é‡Œæ‰€è¯´çš„å¥–åŠ±å¹¶ä¸æ˜¯ä¸€ä¸ªåŠ¨ä½œå•æ­¥çš„å¥–åŠ±ï¼Œè€Œæ˜¯å½“æ•´ä¸ªæ¸¸æˆç»“æŸæ—¶ï¼Œè¿™ä¸ªåŠ¨ä½œæ•´ä½“æ‰€äº§ç”Ÿçš„ä»·å€¼ï¼Œè¿™ä¸ªä»·å€¼æˆ‘ä»¬å«åšadvantageã€‚å› æ­¤æˆ‘ä»¬çš„ç½‘ç»œè¦å­¦ä¹ çš„ç›®æ ‡å°±æ˜¯ï¼šæŒ‰ç…§æ¯ä¸ªåŠ¨ä½œçš„æ¦‚ç‡è¿›è¡Œé€‰æ‹©æ—¶ï¼Œè·å¾—çš„å¥–åŠ±çš„æœŸæœ›å€¼æ˜¯æœ€å¤§çš„ã€‚</p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/428b640046aa">https://www.jianshu.com/p/428b640046aa</a></p>
<h5 id="ç­–ç•¥æ¢¯åº¦"><a href="#ç­–ç•¥æ¢¯åº¦" class="headerlink" title="ç­–ç•¥æ¢¯åº¦"></a>ç­–ç•¥æ¢¯åº¦</h5><p>åœ¨PGç®—æ³•ä¸­ï¼Œæˆ‘ä»¬çš„Agentåˆè¢«ç§°ä¸ºActorï¼ŒActorå¯¹äºä¸€ä¸ªç‰¹å®šçš„ä»»åŠ¡ï¼Œéƒ½æœ‰è‡ªå·±çš„ä¸€ä¸ªç­–ç•¥Ï€ï¼Œç­–ç•¥Ï€é€šå¸¸ç”¨ä¸€ä¸ªç¥ç»ç½‘ç»œè¡¨ç¤ºï¼Œå…¶å‚æ•°ä¸ºÎ¸ã€‚ä»ä¸€ä¸ªç‰¹å®šçš„çŠ¶æ€stateå‡ºå‘ï¼Œä¸€ç›´åˆ°ä»»åŠ¡çš„ç»“æŸï¼Œè¢«ç§°ä¸ºä¸€ä¸ªå®Œæ•´çš„eposideï¼Œåœ¨æ¯ä¸€æ­¥ï¼Œæˆ‘ä»¬éƒ½èƒ½è·å¾—ä¸€ä¸ªå¥–åŠ±rï¼Œä¸€ä¸ªå®Œæ•´çš„ä»»åŠ¡æ‰€è·å¾—çš„æœ€ç»ˆå¥–åŠ±è¢«ç§°ä¸ºRã€‚è¿™æ ·ï¼Œä¸€ä¸ªæœ‰Tä¸ªæ—¶åˆ»çš„eposideï¼ŒActorä¸æ–­ä¸ç¯å¢ƒäº¤äº’ï¼Œå½¢æˆå¦‚ä¸‹çš„åºåˆ—Ï„ï¼š</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316210642889.png" alt="image-20210316210642889"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210311213430270.png" alt="image-20210311213430270"></p>
<p>è¿™æ ·ä¸€ä¸ªåºåˆ—Ï„æ˜¯ä¸ç¡®å®šçš„ï¼Œå› ä¸ºActoråœ¨ä¸åŒstateä¸‹æ‰€é‡‡å–çš„actionå¯èƒ½æ˜¯ä¸åŒçš„ï¼Œä¸€ä¸ªåºåˆ—Ï„å‘ç”Ÿçš„æ¦‚ç‡ä¸ºï¼š</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210311213447597.png" alt="image-20210311213447597"></p>
<p>åºåˆ—Ï„æ‰€è·å¾—çš„å¥–åŠ±ä¸ºæ¯ä¸ªé˜¶æ®µæ‰€å¾—åˆ°çš„å¥–åŠ±çš„å’Œï¼Œç§°ä¸ºR(Ï„)ã€‚å› æ­¤ï¼Œåœ¨Actorçš„ç­–ç•¥ä¸ºÏ€çš„æƒ…å†µä¸‹ï¼Œæ‰€èƒ½è·å¾—çš„æœŸæœ›å¥–åŠ±ä¸ºï¼š</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210311213514694.png" alt="image-20210311213514694"></p>
<p>è€Œæˆ‘ä»¬çš„æœŸæœ›æ˜¯è°ƒæ•´Actorçš„ç­–ç•¥Ï€ï¼Œä½¿å¾—æœŸæœ›å¥–åŠ±æœ€å¤§åŒ–ï¼Œäºæ˜¯æˆ‘ä»¬æœ‰äº†ç­–ç•¥æ¢¯åº¦çš„æ–¹æ³•ï¼Œæ—¢ç„¶æˆ‘ä»¬çš„æœŸæœ›å‡½æ•°å·²ç»æœ‰äº†ï¼Œæˆ‘ä»¬åªè¦ä½¿ç”¨æ¢¯åº¦æå‡çš„æ–¹æ³•æ›´æ–°æˆ‘ä»¬çš„ç½‘ç»œå‚æ•°Î¸ï¼ˆå³æ›´æ–°ç­–ç•¥Ï€ï¼‰å°±å¥½äº†ï¼Œæ‰€ä»¥é—®é¢˜çš„é‡ç‚¹å˜ä¸ºäº†æ±‚å‚æ•°çš„æ¢¯åº¦ã€‚æ¢¯åº¦çš„æ±‚è§£è¿‡ç¨‹å¦‚ä¸‹ï¼š</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316210915795.png" alt="image-20210316210915795"></p>
<p>é¦–å…ˆåˆ©ç”¨logå‡½æ•°æ±‚å¯¼çš„ç‰¹ç‚¹è¿›è¡Œè½¬åŒ–ï¼Œéšåç”¨Næ¬¡é‡‡æ ·çš„å¹³å‡å€¼æ¥è¿‘ä¼¼æœŸæœ›ï¼Œæœ€åï¼Œæˆ‘ä»¬å°†pÎ¸å±•å¼€ï¼Œå°†ä¸Î¸æ— å…³çš„é¡¹å»æ‰ï¼Œå³å¾—åˆ°äº†æœ€ç»ˆçš„ç»“æœã€‚</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210311213315228.png" alt="image-20210311213315228"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210311213339458.png" alt="image-20210311213339458"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316211600007.png" alt="image-20210316211600007"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316211642310.png" alt="image-20210316211642310"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316211734692.png" alt="image-20210316211734692"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316211747501.png" alt="image-20210316211747501"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210316211839980.png" alt="image-20210316211821933"></p>
<p>policy gradient çš„Agentçš„å®ç°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> maze_env_drl <span class="keyword">import</span> Maze</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PolicyGradient</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_actions, n_features, learning_rate=<span class="number">0.01</span>, reward_decay=<span class="number">0.95</span>, output_graph=<span class="literal">False</span></span>):</span><br><span class="line">        self.n_actions = n_actions</span><br><span class="line">        self.n_features = n_features</span><br><span class="line">        self.lr = learning_rate     <span class="comment"># å­¦ä¹ ç‡</span></span><br><span class="line">        self.gamma = reward_decay   <span class="comment"># reward é€’å‡ç‡</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#å› ä¸ºéœ€è¦æ¨¡æ‹Ÿæ•´ä¸ªå›åˆæ‰èƒ½å¾—åˆ°æœ€ç»ˆå¥–åŠ±ï¼Œæ‰èƒ½è¿›è¡Œç½‘ç»œå­¦ä¹ ï¼Œæ‰€ä»¥éœ€è¦å°†è¾¾åˆ°ç»ˆç‚¹ç‚¹æ•´ä¸ªåºåˆ—çš„çŠ¶æ€ã€åŠ¨ä½œã€å¥–åŠ±è®°å½•ä¸‹æ¥</span></span><br><span class="line">        self.ep_obs, self.ep_as, self.ep_rs = [], [], []    <span class="comment">#è¿™æ˜¯æˆ‘ä»¬å­˜å‚¨ å›åˆä¿¡æ¯çš„ list</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#ä¸‹é¢ä¸ä¹‹å‰æ˜¯ä¸€æ ·çš„</span></span><br><span class="line">        self._build_net()  <span class="comment">#å»ºç«‹ç½‘ç»œ</span></span><br><span class="line">        self.sess = tf.Session()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> output_graph:</span><br><span class="line">            tf.summary.FileWriter(<span class="string">&quot;logs/&quot;</span>, self.sess.graph)</span><br><span class="line">        </span><br><span class="line">        self.sess.run(tf.global_variables_initializer())</span><br><span class="line">        </span><br><span class="line">    <span class="comment">#ä¸æ­¤å‰ä¸åŒä¹‹å‰å‚¨å­˜è®°å¿†åˆ©ç”¨çš„æ˜¯replay bufferæœºåˆ¶ã€‚å­˜å‚¨å†…å®¹åˆ†å¯èƒ½æ¥è‡ªä¸åŒæ‰§è¡Œåºåˆ—å’Œä¸åŒå‚æ•°çš„ç¥ç»ç½‘ç»œ</span></span><br><span class="line">    <span class="comment">#æ­¤å¤„åªæ˜¯ä¸ºäº†å‚¨å­˜è¾¾åˆ°ç»ˆç‚¹å‰ä¸€ä¸ªç³»åˆ—çš„åŠ¨ä½œ</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">store_transition</span>(<span class="params">self, s, a, r</span>):</span><br><span class="line">        self.ep_obs.append(s)</span><br><span class="line">        self.ep_as.append(a)</span><br><span class="line">        self.ep_rs.append(r)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#æ„å»ºç½‘ç»œï¼Œå› ä¸ºç›´æ¥èµ°åˆ°ç»ˆç‚¹ï¼Œå¥–åŠ±æ˜¯å¯ä»¥è§‚å¯Ÿçš„ï¼Œä¸å†éœ€è¦target_workå»æ±‚st+1çš„æœ€å¤§ä»·å€¼</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_net</span>(<span class="params">self</span>):</span><br><span class="line">        tf.reset_default_graph()  <span class="comment">#æ¸…ç©ºè®¡ç®—å›¾</span></span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;input&#x27;</span>):</span><br><span class="line">            self.tf_obs = tf.placeholder(tf.float32, [<span class="literal">None</span>, self.n_features], name=<span class="string">&quot;observations&quot;</span>)  <span class="comment">#æ¥æ”¶observation</span></span><br><span class="line">            <span class="comment">#æ ‡ç­¾ç»´åº¦ä¸º[batch_size, 1]ã€‚æ ‡ç­¾æ˜¯å…·ä½“åŠ¨ä½œï¼Œä¸æ˜¯æ¦‚ç‡</span></span><br><span class="line">            self.tf_acts = tf.placeholder(tf.int32, [<span class="literal">None</span>, ], name=<span class="string">&quot;actions_num&quot;</span>)   <span class="comment"># æ¥æ”¶æˆ‘ä»¬åœ¨è¿™ä¸ªå›åˆä¸­é€‰è¿‡çš„actions</span></span><br><span class="line">            <span class="comment">#æ¥æ”¶æ¯ä¸ªstate-actionæ‰€å¯¹åº”çš„value(é€šè¿‡rewardè®¡ç®—),æ³¨æ„æ­¤å¤„ä¸æ˜¯å•æ­¥çš„å¥–åŠ±ï¼Œè€Œæ˜¯æ•´ä¸ªä¸€äº›åˆ—åŠ¨ä½œçš„å¥–åŠ±,vt=æœ¬reward + è¡°å‡çš„æœªæ¥reward</span></span><br><span class="line">            self.tf_vt = tf.placeholder(tf.float32, [<span class="literal">None</span>, ], name=<span class="string">&quot;actions_value&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#æƒé‡åˆå§‹åŒ–æ–¹å¼</span></span><br><span class="line">        w_initializer = tf.random_normal_initializer(<span class="number">0.</span>,<span class="number">0.3</span>)  </span><br><span class="line">        b_initializer = tf.constant_initializer(<span class="number">0.1</span>)</span><br><span class="line">        n_l1 = <span class="number">10</span>  <span class="comment">#n_l1ä¸ºnetworkéšè—å±‚ç¥ç»å…ƒçš„ä¸ªæ•° </span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;lay1&quot;</span>):</span><br><span class="line">            w1 = tf.get_variable(<span class="string">&#x27;w1&#x27;</span>, [self.n_features, n_l1], initializer=w_initializer)</span><br><span class="line">            b1 = tf.get_variable(<span class="string">&#x27;b1&#x27;</span>, [<span class="number">1</span>, n_l1], initializer=b_initializer)</span><br><span class="line">            l1 = tf.nn.tanh(tf.matmul(self.tf_obs, w1)+b1)</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;lay2&quot;</span>):</span><br><span class="line">            w2 = tf.get_variable(<span class="string">&#x27;w2&#x27;</span>, [n_l1, self.n_actions], initializer=w_initializer)</span><br><span class="line">            b2 = tf.get_variable(<span class="string">&#x27;b2&#x27;</span>, [<span class="number">1</span>, self.n_actions], initializer=b_initializer)</span><br><span class="line">            output = tf.matmul(l1, w2)+b2</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#ploicy gradientæ±‚è§£åœ¨ä¸€ä¸ªçŠ¶æ€ä¸‹æ¯ä¸ªåŠ¨ä½œçš„æ¦‚ç‡ï¼Œå› æ­¤ä½¿ç”¨softmaxå‡ºåŠ¨ä½œæ¦‚ç‡</span></span><br><span class="line">        self.all_act_prob = tf.nn.softmax(output)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;loss&#x27;</span>):</span><br><span class="line">            <span class="comment">#äº¤å‰ç†µä½œä¸ºæŸå¤±å‡½æ•°,è®­ç»ƒæ ·æœ¬ä¸­é€‰ä¸­çš„actionå³ä¸ºæˆ‘ä»¬çš„label,å› ä¸ºè¿˜æ²¡æ±‚å‡ºæœ€ç»ˆæŸå¤±,æ­¤å¤„ç”¨reduce_sum</span></span><br><span class="line">            neg_log_prob = -tf.reduce_sum(tf.log(self.all_act_prob)*tf.one_hot(self.tf_acts, self.n_actions), axis=<span class="number">1</span>)</span><br><span class="line">            <span class="comment">#å¯æ˜¯è§†ä¸ºå½“å‰è¿™ä¸ªå±€éƒ¨æŸå¤±*å¯¹åº”æƒé‡ï¼Œå¯ä»¥çœ‹åˆ°state-actionçš„valueè¶Šå¤§ï¼Œæƒé‡è¶Šå¤§</span></span><br><span class="line">            <span class="comment">#å¯ä»¥è®¤ä¸ºstate-actionçš„valueè¶Šå¤§ï¼Œå°±è¶Šä¼šé¡ºç€è¿™ä¸ªæ¢¯åº¦ä¸‹é™ï¼Œè¿™ä¸ªåŠ¨ä½œå°±è¶Šå¯ä¿¡</span></span><br><span class="line">            <span class="comment">#è‹¥ä¸åŠ åŸºå‡†çº¿bä¸ºå¦‚ä¸‹æ–¹å¼ï¼š</span></span><br><span class="line">            <span class="comment">#loss = tf.reduce_mean(neg_log_prob * (self.tf_vt))</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">#åŠ å…¥åŸºå‡†çº¿bçš„æŸå¤±</span></span><br><span class="line">            loss = tf.reduce_mean(neg_log_prob * (self.tf_vt-tf.reduce_mean(self.tf_vt)))</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;train&#x27;</span>):</span><br><span class="line">            self.train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#ä¹‹å‰DQNæ ¹æ®æœ€å¤§åŠ¨ä½œä»·å€¼é€‰æ‹©åŠ¨ä½œï¼Œploicy gradientæ ¹æ®ç½‘ç»œè¾“å‡ºçš„åŠ¨ä½œæ¦‚ç‡ï¼Œä¾ç…§æ¦‚ç‡é€‰æ‹©åŠ¨ä½œ</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">choose_action</span>(<span class="params">self, observation</span>):</span><br><span class="line">        <span class="comment"># æ‰€æœ‰actionçš„æ¦‚ç‡</span></span><br><span class="line">        prob_weights = self.sess.run(self.all_act_prob, feed_dict=&#123;self.tf_obs: observation[np.newaxis, :]&#125;)</span><br><span class="line">        <span class="comment">#æŒ‰ç…§æ¦‚ç‡é€‰æ‹©åŠ¨ä½œ</span></span><br><span class="line">        action = np.random.choice(<span class="built_in">range</span>(prob_weights.shape[<span class="number">1</span>]), p=prob_weights.ravel())</span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#ç”¨äºè®¡ç®—å›åˆçš„state-action value</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_discount_and_norm_rewards</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment">#å…ˆè®¡ç®—å•æ­¥çš„å¥–åŠ±ï¼Œåœ¨é€æ­¥å°†åé¢çš„å¥–åŠ±é€æ­¥è¡°å‡åŠ åˆ°å‰é¢</span></span><br><span class="line">        discounted_ep_rs = np.zeros_like(self.ep_rs)</span><br><span class="line">        running_add = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#å°†åé¢çš„å¥–åŠ±é€æ­¥è¡°å‡åŠ åˆ°å‰é¢</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(self.ep_rs))):</span><br><span class="line">            running_add = running_add * self.gamma + self.ep_rs[t]</span><br><span class="line">            discounted_ep_rs[t] = running_add</span><br><span class="line">            </span><br><span class="line">        <span class="comment">#é˜²æ­¢æ¯ä¸ªå›åˆè®¡ç®—å‡ºçš„å¥–åŠ±é‡çº²ä¸åŒï¼Œè¿›è¡Œæ­£æ€æ ‡å‡†åŒ–</span></span><br><span class="line">        discounted_ep_rs = np.array(discounted_ep_rs,dtype=np.<span class="built_in">float</span>) </span><br><span class="line">        discounted_ep_rs -= np.mean(discounted_ep_rs)</span><br><span class="line">        discounted_ep_rs /= np.std(discounted_ep_rs)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> discounted_ep_rs</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">learn</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment">#å› ä¸ºè®­ç»ƒæ—¶ä¼ å…¥çš„ä¸æ˜¯åŠ¨ä½œå•æ­¥å¥–åŠ±ï¼Œæ‰§è¡Œå®ŒåŠ¨ä½œåçš„æ•´ä½“å¥–åŠ±ï¼Œå› æ­¤å…ˆè®¡ç®—æ‰§è¡Œå®ŒåŠ¨ä½œåçš„æ•´ä½“å¥–åŠ±</span></span><br><span class="line">        discounted_ep_rs_norm = self._discount_and_norm_rewards()</span><br><span class="line">        <span class="comment">#np.vstack(self.ep_obs)çš„shape=[None, n_obs]ï¼Œnp.array(self.ep_as)çš„shape=[None,]ï¼Œdiscounted_ep_rs_normçš„shape=[None,]</span></span><br><span class="line">        <span class="comment">#æ¯æ¬¡çš„è®­ç»ƒæ ·æœ¬ç›¸å½“äºä¸€å’Œå®Œæ•´æµç¨‹çŠ¶æ€å’Œå¯¹åº”çš„åŠ¨ä½œä»¥åŠå¯¹åº”å¥–åŠ±ã€‚</span></span><br><span class="line">        self.sess.run(self.train_op, feed_dict=&#123;self.tf_obs: np.vstack(self.ep_obs),self.tf_acts: np.array(self.ep_as),self.tf_vt: discounted_ep_rs_norm&#125;)</span><br><span class="line">        <span class="comment">#æ¬¡å›åˆåŠ¨ä½œå·²ç»è®­ç»ƒå®Œï¼Œæ¸…ç©ºè®°å¿†ã€‚ä¸‹æ¬¡è®­ç»ƒéœ€è¦é‡æ–°äº§ç”Ÿè®­ç»ƒæ ·æœ¬</span></span><br><span class="line">        self.ep_obs, self.ep_as, self.ep_rs = [], [], []</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#è¿”å›è¿™ä¸€å›åˆçš„state-action value</span></span><br><span class="line">        <span class="keyword">return</span> discounted_ep_rs_norm  </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_maze</span>(<span class="params">RENDER</span>):</span><br><span class="line">    <span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3000</span>):</span><br><span class="line">        <span class="comment"># åˆå§‹åŒ–ç¯å¢ƒ</span></span><br><span class="line">        observation = env.reset()</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">if</span> RENDER:</span><br><span class="line">                <span class="comment"># åˆ·æ–°ç¯å¢ƒ</span></span><br><span class="line">                env.render()</span><br><span class="line">            <span class="comment"># DQN æ ¹æ®è§‚æµ‹å€¼é€‰æ‹©è¡Œä¸º</span></span><br><span class="line">            action = RL.choose_action(observation)</span><br><span class="line">            <span class="comment"># ç¯å¢ƒæ ¹æ®è¡Œä¸ºç»™å‡ºä¸‹ä¸€ä¸ªstate, reward,æ˜¯å¦ç»ˆæ­¢</span></span><br><span class="line">            observation_, reward, done = env.step(action)</span><br><span class="line">            <span class="comment">#å­˜å‚¨è®°å¿†</span></span><br><span class="line">            RL.store_transition(observation, action, reward)</span><br><span class="line">            <span class="comment">#çŸ¥é“è·å¾—æœ€ç»ˆå¥–åŠ±æ‰èƒ½è¿›è¡Œè®­ç»ƒï¼Œè¿™æ˜¯MCçš„æ–¹æ³•</span></span><br><span class="line">            <span class="keyword">if</span> done:</span><br><span class="line">                ep_rs_sum=<span class="built_in">sum</span>(RL.ep_rs)</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> <span class="string">&#x27;running_reward&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> <span class="built_in">locals</span>():</span><br><span class="line">                    running_reward = ep_rs_sum</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    running_reward = running_reward * <span class="number">0.99</span> + ep_rs_sum * <span class="number">0.01</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> running_reward&gt; DISPLAY_REWARD_THRESHOLD:</span><br><span class="line">                    RENDER=<span class="literal">True</span></span><br><span class="line">                </span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;episode:&quot;</span>, episode, <span class="string">&quot;  reward:&quot;</span>, <span class="built_in">int</span>(running_reward))</span><br><span class="line">                </span><br><span class="line">                vt = RL.learn()</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> episode==<span class="number">0</span>:</span><br><span class="line">                    plt.plot(vt)    <span class="comment"># plotè¿™ä¸ªå›åˆçš„vt</span></span><br><span class="line">                    plt.xlabel(<span class="string">&#x27;episode steps&#x27;</span>)</span><br><span class="line">                    plt.ylabel(<span class="string">&#x27;normalized state-action value&#x27;</span>)</span><br><span class="line">                    plt.show()</span><br><span class="line">                <span class="keyword">break</span>   <span class="comment">#æ­¤æ¬¡æ¨¡æ‹Ÿå®Œæ¯•</span></span><br><span class="line">                </span><br><span class="line">            observation = observation_  <span class="comment">#è¿˜æ²¡æœ‰è·å–å¥–åŠ±ï¼Œå»è¦ç»§ç»­æ‰§è¡Œæ¨¡æ‹Ÿ</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    RENDER=<span class="literal">False</span></span><br><span class="line">    DISPLAY_REWARD_THRESHOLD=<span class="number">300</span></span><br><span class="line">    env = Maze() </span><br><span class="line">    </span><br><span class="line">    RL = PolicyGradient(n_actions=env.n_actions, n_features=env.n_features, learning_rate=<span class="number">0.02</span>, reward_decay=<span class="number">0.99</span>, output_graph=<span class="literal">True</span>)</span><br><span class="line">    run_maze(RENDER)</span><br></pre></td></tr></table></figure>

<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210317112639995.png" alt="image-20210317112639995"></p>
<p>å¯ä»¥çœ‹å‡ºpolicy gradientæ˜¯åŸºäºå›åˆæ›´æ–°çš„ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦éœ€è¦å¾ˆå¤§çš„è€å¿ƒå’Œç¯å¢ƒäº§ç”Ÿäº¤äº’æ ·æœ¬ï¼Œè¿›è¡Œå›åˆè®­ç»ƒï¼Œå¹¶ä¸”ç”±äºæ¯ä¸ªå›åˆæ˜¯ä¸ç¨³å®šçš„ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦çš„å¤§é‡çš„æ ·æœ¬</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210317155054551.png" alt="image-20210317155054551"></p>
<p>Q-learningå­¦ä¹ çš„æ˜¯æ¯ä¸ªåŠ¨ä½œçš„ä»·å€¼ï¼Œè¦æ±‚åŠ¨ä½œå¿…é¡»æ˜¯ç¦»æ•£çš„ã€‚</p>
<p>policy gradientå’ŒQ-learningéƒ½æœ‰å„è‡ªçš„ä¼˜ç¼ºç‚¹ã€‚æˆ‘ä»¬å¯ä»¥å°†ä¸¤è€…æ•´åˆèµ·æ¥ï¼Œå³è®°å¿†ä½¿ç”¨off-policyçš„å­¦ä¹ ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨è¿ç»­çš„åŠ¨ä½œã€‚</p>
<p>ä¸‹é¢ä¸¤æ®µè¯æ‘˜è‡ªè«çƒ¦pythonçš„å¼ºåŒ–å­¦ä¹ æ•™ç¨‹ï¼šActor-Critic çš„ Actor çš„å‰ç”Ÿæ˜¯ Policy Gradients, è¿™èƒ½è®©å®ƒæ¯«ä¸è´¹åŠ›åœ°åœ¨è¿ç»­åŠ¨ä½œä¸­é€‰å–åˆé€‚çš„åŠ¨ä½œ, è€Œ Q-learning åšè¿™ä»¶äº‹ä¼šç˜«ç—ª. é‚£ä¸ºä»€ä¹ˆä¸ç›´æ¥ç”¨ Policy Gradients å‘¢? åŸæ¥ Actor Critic ä¸­çš„ Critic çš„å‰ç”Ÿæ˜¯ Q-learning æˆ–è€…å…¶ä»–çš„ ä»¥å€¼ä¸ºåŸºç¡€çš„å­¦ä¹ æ³• , èƒ½è¿›è¡Œå•æ­¥æ›´æ–°, è€Œä¼ ç»Ÿçš„ Policy Gradients åˆ™æ˜¯å›åˆæ›´æ–°, è¿™é™ä½äº†å­¦ä¹ æ•ˆç‡ã€‚</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210317155324880.png" alt="image-20210317155324880"></p>
<p>Actor å’Œ Critic, ä»–ä»¬éƒ½èƒ½ç”¨ä¸åŒçš„ç¥ç»ç½‘ç»œæ¥ä»£æ›¿ . åœ¨ Policy Gradients çš„å½±ç‰‡ä¸­æåˆ°è¿‡, ç°å®ä¸­çš„å¥–æƒ©ä¼šå·¦å³ Actor çš„æ›´æ–°æƒ…å†µ. Policy Gradients ä¹Ÿæ˜¯é ç€è¿™ä¸ªæ¥è·å–é€‚å®œçš„æ›´æ–°. é‚£ä¹ˆä½•æ—¶ä¼šæœ‰å¥–æƒ©è¿™ç§ä¿¡æ¯èƒ½ä¸èƒ½è¢«å­¦ä¹ å‘¢? è¿™çœ‹èµ·æ¥ä¸å°±æ˜¯ ä»¥å€¼ä¸ºåŸºç¡€çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•åšè¿‡çš„äº‹å—. é‚£æˆ‘ä»¬å°±æ‹¿ä¸€ä¸ª Critic å»å­¦ä¹ è¿™äº›å¥–æƒ©æœºåˆ¶, å­¦ä¹ å®Œäº†ä»¥å. ç”± Actor æ¥æŒ‡æ‰‹ç”»è„š, ç”± Critic æ¥å‘Šè¯‰ Actor ä½ çš„é‚£äº›æŒ‡æ‰‹ç”»è„šå“ªäº›æŒ‡å¾—å¥½, å“ªäº›æŒ‡å¾—å·®, Critic é€šè¿‡å­¦ä¹ ç¯å¢ƒå’Œå¥–åŠ±ä¹‹é—´çš„å…³ç³», èƒ½çœ‹åˆ°ç°åœ¨æ‰€å¤„çŠ¶æ€çš„æ½œåœ¨å¥–åŠ±, æ‰€ä»¥ç”¨å®ƒæ¥æŒ‡ç‚¹ Actor ä¾¿èƒ½ä½¿ Actor æ¯ä¸€æ­¥éƒ½åœ¨æ›´æ–°, å¦‚æœä½¿ç”¨å•çº¯çš„ Policy Gradients, Actor åªèƒ½ç­‰åˆ°å›åˆç»“æŸæ‰èƒ½å¼€å§‹æ›´æ–°ã€‚</p>
<p>ä»¥å‰æˆ‘ä»¬ç”¨è¿‡å›åˆçš„å¥–åŠ±æ¥è¿›è¡Œpolicy gradientçš„æ›´æ–°ï¼ŒActor-Criticå°†å›åˆå¥–åŠ±æ›¿æ¢æˆåŠ¨ä½œçš„ä»·å€¼ï¼Œæ¥å¯¹ç½‘ç»œè¿›è¡Œå­¦ä¹ ï¼Œè‡ªç„¶å°±å°†Q-learningç»“åˆäº†èµ·æ¥ï¼š</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210317155528931.png" alt="image-20210317155528931"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210317155542474.png" alt="image-20210317155542474"></p>
<p>åœ¨PGç­–ç•¥ä¸­ï¼Œå¦‚æœæˆ‘ä»¬ç”¨Qå‡½æ•°æ¥ä»£æ›¿Rï¼ŒåŒæ—¶æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªCriticç½‘ç»œæ¥è®¡ç®—Qå‡½æ•°å€¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¾—åˆ°äº†Actor-Criticæ–¹æ³•ã€‚Actorå‚æ•°çš„æ¢¯åº¦å˜ä¸ºï¼š</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210311221748445.png" alt="image-20210311221748445"></p>
<p>æ­¤æ—¶çš„Criticæ ¹æ®ä¼°è®¡çš„Qå€¼å’Œå®é™…Qå€¼çš„<strong>å¹³æ–¹è¯¯å·®</strong>è¿›è¡Œæ›´æ–°ï¼Œå¯¹Criticæ¥è¯´ï¼Œå…¶lossä¸ºï¼š</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210311221814333.png" alt="image-20210311221814333"></p>
<p>ACä»£ç çš„å®ç°åœ°å€ä¸ºï¼š<a target="_blank" rel="noopener" href="https://github.com/princewen/tensorflow_practice/tree/master/RL/Basic-AC-Demo">https://github.com/princewen/tensorflow_practice/tree/master/RL/Basic-AC-Demo</a></p>
<h1 id="Advantage-Actor-Critic-A2C"><a href="#Advantage-Actor-Critic-A2C" class="headerlink" title="Advantage Actor-Critic(A2C)"></a>Advantage Actor-Critic(A2C)</h1><p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210317155623826.png" alt="image-20210317155623826"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210317155634647.png" alt="image-20210317155634647"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210317155755636.png" alt="image-20210317155755636"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210317155831237.png" alt="image-20210317155831237"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210317155955489.png" alt="image-20210317155955489"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210317160425425.png" alt="image-20210317160425425"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210317160942244.png" alt="image-20210317160942244"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210317162607727.png" alt="image-20210317162607727"></p>
<p>æœ¬æ–‡åŸºäºå¦‚ä¸‹æ¶æ„è¿›è¡ŒAdvantage Actor-Criticçš„Agentå®ç°ã€‚å…¶ä¸­Actorå’ŒCriticçš„ç¬¬ä¸€å±‚æƒé‡å…±äº«ï¼š</p>
<h4 id="Q-learning"><a href="#Q-learning" class="headerlink" title="Q-learning"></a>Q-learning</h4><p>Q-learningæ˜¯ä¸€ç§value_basedçš„æ–¹æ³•ã€‚</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20210312203323472.png" alt="image-20210312203323472"></p>
</div><div class="tags"><a href="/peaky/tags/%E5%AD%A6%E4%B9%A0/"><i class="fa fa-tag"></i>å­¦ä¹ </a><a href="/peaky/tags/RL/"><i class="fa fa-tag"></i>RL</a></div><div class="post-nav"><a class="pre" href="/peaky/2021/05/05/a54293f2.html"></a><a class="next" href="/peaky/2021/03/01/514027fa.html"></a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == 'true' ? true : false;
var verify = 'false' == 'true' ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'c2tSICknvMNwQOvqeqh8wYoi-9Nh9j0Va',
  appKey:'geSzJMrX46ogsQR590PTiGPF',
  placeholder:'Just so so',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Kategorien</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/MIUI/">MIUI</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/MarkDown/">MarkDown</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/RL/">RL</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/%E5%AD%A6%E4%B9%A0/">å­¦ä¹ </a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/%E5%AF%BC%E8%88%AA/">å¯¼èˆª</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/%E6%95%99%E7%A8%8B/">æ•™ç¨‹</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/%E7%94%B5%E8%84%91/">ç”µè„‘</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/%E7%BC%96%E7%A8%8B/">ç¼–ç¨‹</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/%E8%BD%AF%E4%BB%B6/">è½¯ä»¶</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/peaky/tags/%E6%B5%8F%E8%A7%88%E5%99%A8/" style="font-size: 15px;">æµè§ˆå™¨</a> <a href="/peaky/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/peaky/tags/%E6%95%99%E7%A8%8B/" style="font-size: 15px;">æ•™ç¨‹</a> <a href="/peaky/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/peaky/tags/%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">å­¦ä¹ </a> <a href="/peaky/tags/MIUI/" style="font-size: 15px;">MIUI</a> <a href="/peaky/tags/MarkDown/" style="font-size: 15px;">MarkDown</a> <a href="/peaky/tags/%E8%AF%AD%E6%B3%95/" style="font-size: 15px;">è¯­æ³•</a> <a href="/peaky/tags/python/" style="font-size: 15px;">python</a> <a href="/peaky/tags/RL/" style="font-size: 15px;">RL</a> <a href="/peaky/tags/%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">ç¼–ç¨‹</a> <a href="/peaky/tags/%E5%AF%BC%E8%88%AA/" style="font-size: 15px;">å¯¼èˆª</a> <a href="/peaky/tags/%E8%BD%AF%E4%BB%B6/" style="font-size: 15px;">è½¯ä»¶</a> <a href="/peaky/tags/%E7%94%B5%E8%84%91/" style="font-size: 15px;">ç”µè„‘</a> <a href="/peaky/tags/%E6%97%A5%E5%B8%B8/" style="font-size: 15px;">æ—¥å¸¸</a> <a href="/peaky/tags/springboot/" style="font-size: 15px;">springboot</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Letzte</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/peaky/2022/03/03/4a17b156.html">Hello World</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2022/03/01/8d39085b.html">Linuxéƒ¨ç½²gitä¸Nodejs</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2021/08/27/87d44b9d.html">MIUIæ•™ç¨‹</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2021/06/01/9211474f.html">linux commd</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2021/05/05/a54293f2.html">Springbootç¬”è®°</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2021/03/15/217f21be.html">DRLç¬”è®°</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2021/03/01/514027fa.html">Hexoéƒ¨ç½²åˆ°é˜¿é‡Œäº‘OSSä¸Š</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2021/01/28/ef00c80b.html">LayUIå…¥é—¨</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2021/01/23/44737761.html">å°ç±³æ‰‹æœºåˆ·æœºå…¥é—¨æŒ‡åŒ—ï¼ˆå°ç™½å‘ï¼‰</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2021/01/20/a2f6ccf6.html">layuiAdmin pro v1.x ã€å•é¡µç‰ˆã€‘å¼€å‘è€…æ–‡æ¡£</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Blogroll</i></div><ul></ul><a href="http://www.example1.com/" title="ç›¸å…³é“¾æ¥" target="_blank">ç›¸å…³é“¾æ¥</a><ul></ul><a href="http://www.example2.com/" title="ç›¸å…³é“¾æ¥" target="_blank">ç›¸å…³é“¾æ¥</a><ul></ul><a href="http://www.example3.com/" title="ç›¸å…³é“¾æ¥" target="_blank">ç›¸å…³é“¾æ¥</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright Â© 2022 <a href="/peaky/." rel="nofollow">NoteBook.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/peaky/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/peaky/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/peaky/css/search.css?v=1.0.0"><script type="text/javascript" src="/peaky/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/peaky/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/peaky/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/peaky/js/smartresize.js?v=1.0.0"></script></div></body></html>