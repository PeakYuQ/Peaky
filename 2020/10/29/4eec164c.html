<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="There is no description"><title>入门深度学习 | NoteBook</title><link rel="stylesheet" type="text/css" href="/peaky/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="/peaky/css/dark.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/peaky/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/peaky/favicon.ico"><link rel="apple-touch-icon" href="/peaky/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/peaky/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/peaky/atom.xml"><div class="darkmode-toggle">🌓</div><script>var prefersDarkMode = window.matchMedia('(prefers-color-scheme: dark)');
var toggle = document.querySelector('.darkmode-toggle');
var html = document.querySelector('html');

html.dataset.dark = localStorage.dark || prefersDarkMode.matches;

toggle.addEventListener('click', () => {
localStorage.dark = !(html.dataset.dark == 'true');
html.dataset.dark = localStorage.dark;
});</script><meta name="generator" content="Hexo 6.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">入门深度学习</h1><a id="logo" href="/peaky/.">NoteBook</a><p class="description">Always believe that something wonderful is about to hanppen!</p></div><div id="nav-menu"><a class="current" href="/peaky/."><i class="fa fa-home"> 首页</i></a><a href="/peaky/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/peaky/message/"><i class="fa fa-comments"> 留言</i></a><a href="/peaky/daily/"><i class="fa fa-user"> 日迹</i></a><a href="/peaky/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">入门深度学习</h1><div class="post-meta">2020-10-29<span> | </span><span class="category"><a href="/peaky/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 2.1k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 7</span><span class="post-meta-item-text"> 分钟</span></span></span></div><a class="disqus-comment-count" href="/peaky/2020/10/29/4eec164c.html#vcomment"><span class="valine-comment-count" data-xid="/peaky/2020/10/29/4eec164c.html"></span><span> 条评论</span></a><div class="post-content"><h2 id="感知器"><a href="#感知器" class="headerlink" title="感知器"></a>感知器</h2><p>感知机是二分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别（分别取+1和-1），属于判别模型。</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/clip_image001.jpg" alt="img"></p>
<p>​                                                                                                图1 模型</p>
<span id="more"></span>

<p>如图1所示,假设输入空间（特征向量）是<img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/clip_image002.jpg" alt="img"></p>
<p>，输出空间为f(x)∈{-1，+1},输入x∈X表示实例的特征向量，对应于输入空间的点，输出表示实例的类别，则由输入空间到输出空间的表达形式为：</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/clip_image003.jpg" alt="img"></p>
<p>其中w，b称为模型的参数，<img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/clip_image002.jpg" alt="img"></p>
<p>称为权值，b称为偏置，w*x表示为w，x的内积，其中</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/clip_image004.jpg" alt="img"></p>
<p>如果我们将sign(x)称之为激活函数,sign(x)将大于0的分为1，小于0的分为-1。</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/clip_image005.jpg" alt="img"></p>
<pre><code>                                                                                 图2 直线分隔超平面
</code></pre>
<p>如图2所示，其中w为法向量，b为截距，此直线用于分离超平面。</p>
<p>问题在于确定w和b，也就是在学习参数w与b，确定了w与b，图上的直线（高维空间下为超平面）也就确定了，那么以后来一个数据点，我用训练好的模型进行预测判断，如果大于0就分类到+1，如果小于0就分类到-1。</p>
<p>解决这个问题首先要找到损失函数，然后转化为最优化问题，用梯度下降等方法进行更新，最终得到我们模型的参数w，b。</p>
<h2 id="线性单元和梯度下降"><a href="#线性单元和梯度下降" class="headerlink" title="线性单元和梯度下降"></a>线性单元和梯度下降</h2><p>感知器有一个问题，当面对的数据集不是线性可分的时候，『感知器规则』可能无法收敛，这意味着我们永远也无法完成一个感知器的训练。</p>
<p>为了解决这个问题，我们使用一个可导的线性函数来替代感知器的阶跃函数，这种感知器就叫做线性单元。线性单元在面对线性不可分的数据集时，会收敛到一个最佳的近似上。</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/clip_image001.png" alt="计算机生成了可选文字: Error ContinuoUS outPUt Nett LinearRegression"></p>
<p>设置线性单元的激活函数为 f(x) &#x3D; x,这样替换了激活函数之后，线性单元将返回一个实数值而不是0,1分类。因此线性单元用来解决回归问题而不是分类问题。</p>
<p>我们可以用这样的一个特征向量来表示他 x&#x3D; (5, IT, 百度, T6)。</p>
<p>既然输入变成了一个具备四个特征的向量，相对应的，仅仅一个参数就不够用了，我们应该使用4个参数w1.w2.w3.w4，每个特征对应一个。这样，我们的模型就变成</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/clip_image002.png" alt="img"></p>
<p>我们还可以把上式写成向量的形式</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201029164315133.png" alt="image-20201029164315133"></p>
<p> 长成这种样子模型就叫做<strong>线性模型</strong></p>
<h3 id="监督学习和无监督学习"><a href="#监督学习和无监督学习" class="headerlink" title="监督学习和无监督学习"></a>监督学习和无监督学习</h3><p><strong>监督学习</strong>，它是说为了训练一个模型，我们要提供这样一堆训练样本：每个训练样本既包括输入特征，也包括对应的输出(输出也叫做<strong>标记，label</strong>)，用这样的样本去训练模型，让模型既看到我们提出的每个问题(输入特征)，也看到对应问题的答案(标记)。当模型看到足够多的样本之后，它就能总结出其中的一些规律。然后，就可以预测那些它没看过的输入所对应的答案了。</p>
<p><strong>无监督学习</strong>，这种方法的训练样本中只有x而没有y。模型可以总结出特征的一些规律，但是无法知道其对应的答案。</p>
<p>现在，让我们只考虑<strong>监督学习</strong></p>
<p>我们当然希望模型计算出来的和真实值越接近越好。</p>
<p>我们可以用差的平方的1&#x2F;2来表示它们的接近程度<img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201029165018288.png" alt="image-20201029165018288"></p>
<p>我们把这个叫做<strong>单个样本</strong>的<strong>误差</strong>。至于为什么前面要乘1&#x2F;2，是为了后面计算方便。</p>
<p>训练数据中会有很多样本，比如N个，我们可以用训练数据中<strong>所有样本</strong>的误差的<strong>和</strong>，来表示模型的误差，也就是</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201029165110285.png" alt="image-20201029165110285"></p>
<p>我们还可以把上面的式子写成和式的形式。使用和式，不光书写起来简单，逼格也跟着暴涨，一举两得。所以一定要写成下面这样</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201029165158119.png" alt="image-20201029165158119"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201029165339763.png" alt="image-20201029165339763"></p>
<p>其中<img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201029165206876.png" alt="image-20201029165206876"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201029165415019.png" alt="image-20201029165415019"></p>
<h3 id="梯度下降优化算法"><a href="#梯度下降优化算法" class="headerlink" title="梯度下降优化算法"></a><a target="_blank" rel="noopener" href="https://www.zybuluo.com/hanbingtao/note/448086">梯度下降优化算法</a></h3><h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><p>近几年卷积神经网络中，激活函数往往不选择sigmoid或tanh函数，而是选择relu函数。</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201029202143966.png" alt="image-20201029202143966"></p>
<p>优势：</p>
<ol>
<li><p><strong>速度快</strong> 和sigmoid函数需要计算指数和倒数相比，relu函数其实就是一个max(0,x)，计算代价小很多。</p>
</li>
<li><p><strong>减轻梯度消失问题</strong> 在使用反向传播算法进行梯度计算时，每经过一层sigmoid神经元，梯度就要乘上一个sigmoid导数，导致梯度越来越小，而relu函数的导数是1，不会导致梯度变小。</p>
</li>
</ol>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201029203235758.png" alt="image-20201029203235758"></p>
<p>常用架构模式为：INPUT -&gt; [[CONV]*N -&gt; POOL?]*M -&gt; [FC]*K    </p>
<p>也就是N个卷积层叠加，然后(可选)叠加一个Pooling层，重复这个结构M次，最后叠加K个全连接层。</p>
<h3 id="卷积层输出值的计算"><a href="#卷积层输出值的计算" class="headerlink" title="卷积层输出值的计算"></a>卷积层输出值的计算</h3><p>我们用一个简单的例子来讲述如何计算<strong>卷积</strong>，然后，我们抽象出<strong>卷积层</strong>的一些重要概念和计算方法。</p>
<p>假设有一个5 * 5的图像，使用一个3 * 3的filter进行卷积，想得到一个3 * 3的Feature Map，如下所示：</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201029204011473.png" alt="image-20201029204011473"></p>
<p><a target="_blank" rel="noopener" href="https://www.zybuluo.com/hanbingtao/note/485480">卷积详细计算过程</a></p>
<h3 id="Pooling层输出值的计算"><a href="#Pooling层输出值的计算" class="headerlink" title="Pooling层输出值的计算"></a>Pooling层输出值的计算</h3><p>Pooling层主要的作用是<strong>下采样</strong>，通过去掉Feature Map中不重要的样本，进一步减少参数数量。Pooling的方法很多，最常用的是<strong>Max Pooling</strong>。<strong>Max Pooling</strong>实际上就是在n<em>n的样本中取最大值，作为采样后的样本值。下图是2</em>2 max pooling：</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201029205342560.png" alt="image-20201029205342560"></p>
<p>除了<strong>Max Pooing</strong>之外，常用的还有<strong>Mean Pooling</strong>——取各样本的平均值。</p>
<h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a><a target="_blank" rel="noopener" href="https://zybuluo.com/hanbingtao/note/541458">循环神经网络</a></h2><p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201029210859115.png" alt="image-20201029210859115"></p>
<p>如果把上面有W的那个带箭头的圈去掉，它就变成了最普通的<strong>全连接神经网络</strong>。x是一个向量，它表示<strong>输入层</strong>的值（这里面没有画出来表示神经元节点的圆圈）；s是一个向量，它表示<strong>隐藏层</strong>的值（这里隐藏层面画了一个节点，你也可以想象这一层其实是多个节点，节点数与向量s的维度相同）；U是输入层到隐藏层的<strong>权重矩阵</strong>，o也是一个向量，它表示<strong>输出层</strong>的值；V是隐藏层到输出层的<strong>权重矩阵</strong>。那么，现在我们来看看W是什么。<strong>循环神经网络</strong>的<strong>隐藏层</strong>的值s不仅仅取决于当前这次的输入x，还取决于上一次<strong>隐藏层</strong>的值s。<strong>权重矩阵</strong> W就是<strong>隐藏层</strong>上一次的值作为这一次的输入的权重。</p>
<p>如果我们把上面的图展开，<strong>循环神经网络</strong>也可以画成下面这个样子：</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201029211229733.png" alt="image-20201029211229733"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201029211729617.png" alt="image-20201029211729617"></p>
<p><strong>式1</strong>是<strong>输出层</strong>的计算公式，输出层是一个<strong>全连接层</strong>，也就是它的每个节点都和隐藏层的每个节点相连。V是输出层的<strong>权重矩阵</strong>，g是<strong>激活函数</strong>。式2是隐藏层的计算公式，它是<strong>循环层</strong>。U是输入x的权重矩阵，W是上一次的值作为这一次的输入的<strong>权重矩阵</strong>，f是<strong>激活函数</strong>。</p>
<p>从上面的公式我们可以看出，<strong>循环层</strong>和<strong>全连接层</strong>的区别就是<strong>循环层</strong>多了一个<strong>权重矩阵</strong> W。</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201029212231308.png" alt="image-20201029212231308"></p>
<p>理解 <a target="_blank" rel="noopener" href="https://blog.csdn.net/zhangdamengcsdn/article/details/80200059">向量求导</a></p>
<p>术语 降维</p>
<h2 id="长短时记忆网络-LSTM"><a href="#长短时记忆网络-LSTM" class="headerlink" title="长短时记忆网络(LSTM)"></a><a target="_blank" rel="noopener" href="https://zybuluo.com/hanbingtao/note/581764">长短时记忆网络</a>(LSTM)</h2><p>原始RNN的隐藏层只有一个状态，即h，它对于短期的输入非常敏感。那么，假如我们再增加一个状态，即c，让它来保存长期的状态，那么问题不就解决了么？如下图所示：</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201030165854887.png" alt="image-20201030165854887"></p>
<p>新增加的状态c，称为**单元状态(cell state)**。我们把上图按照时间维度展开：</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201030165911604.png" alt="image-20201030165911604"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201030165940888.png" alt="image-20201030165940888"></p>
<p>LSTM的关键，就是怎样控制长期状态c。在这里，LSTM的思路是使用三个控制开关。第一个开关，负责控制继续保存长期状态c；第二个开关，负责控制把即时状态输入到长期状态c；第三个开关，负责控制是否把长期状态c作为当前的LSTM的输出。三个开关的作用如下图所示：</p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201030170117704.png" alt="image-20201030170117704"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201030170554414.png" alt="image-20201030170554414"></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u012328159/article/details/87907739">GRU</a></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201030213555978.png" alt="image-20201030213555978"></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201030213612331.png" alt="image-20201030213612331"></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u012328159/article/details/87567358">LSTM</a></p>
<p><img src="https://pic-20201016.oss-cn-qingdao.aliyuncs.com/img/image-20201030211205034.png" alt="image-20201030211205034"></p>
</div><div class="tags"><a href="/peaky/tags/RL/"><i class="fa fa-tag"></i>RL</a></div><div class="post-nav"><a class="pre" href="/peaky/2020/12/02/4a098468.html">MarkDown基本语法</a><a class="next" href="/peaky/2020/10/16/7336dcda.html">python常见语法</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/gh/AshinWang/SimpleValine@v0.1/SimpleValine.min.js"></script><script>var notify = 'false' == 'true' ? true : false;
var verify = 'false' == 'true' ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'c2tSICknvMNwQOvqeqh8wYoi-9Nh9j0Va',
  appKey:'geSzJMrX46ogsQR590PTiGPF',
  placeholder:'留下你的足迹~',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/MIUI/">MIUI</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/MarkDown/">MarkDown</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/RL/">RL</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/Study/">Study</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/paper/">paper</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/%E5%AD%A6%E4%B9%A0/">学习</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/%E5%AF%BC%E8%88%AA/">导航</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/%E6%95%99%E7%A8%8B/">教程</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/%E6%97%A5%E8%BF%B9/">日迹</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/%E7%94%B5%E8%84%91/">电脑</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/%E7%BC%96%E7%A8%8B/">编程</a></li><li class="category-list-item"><a class="category-list-link" href="/peaky/categories/%E8%BD%AF%E4%BB%B6/">软件</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/peaky/tags/%E6%B5%8F%E8%A7%88%E5%99%A8/" style="font-size: 15px;">浏览器</a> <a href="/peaky/tags/Study/" style="font-size: 15px;">Study</a> <a href="/peaky/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/peaky/tags/%E6%95%99%E7%A8%8B/" style="font-size: 15px;">教程</a> <a href="/peaky/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/peaky/tags/%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">学习</a> <a href="/peaky/tags/MIUI/" style="font-size: 15px;">MIUI</a> <a href="/peaky/tags/MarkDown/" style="font-size: 15px;">MarkDown</a> <a href="/peaky/tags/%E8%AF%AD%E6%B3%95/" style="font-size: 15px;">语法</a> <a href="/peaky/tags/python/" style="font-size: 15px;">python</a> <a href="/peaky/tags/RL/" style="font-size: 15px;">RL</a> <a href="/peaky/tags/%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">编程</a> <a href="/peaky/tags/%E5%AF%BC%E8%88%AA/" style="font-size: 15px;">导航</a> <a href="/peaky/tags/%E8%BD%AF%E4%BB%B6/" style="font-size: 15px;">软件</a> <a href="/peaky/tags/%E6%97%A5%E8%BF%B9/" style="font-size: 15px;">日迹</a> <a href="/peaky/tags/%E7%94%B5%E8%84%91/" style="font-size: 15px;">电脑</a> <a href="/peaky/tags/%E6%97%A5%E5%B8%B8/" style="font-size: 15px;">日常</a> <a href="/peaky/tags/paper/" style="font-size: 15px;">paper</a> <a href="/peaky/tags/springboot/" style="font-size: 15px;">springboot</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/peaky/2022/04/09/1e5d734c.html">日迹</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2022/03/28/d285d8df.html">EC Abstract</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2022/03/20/9f2153c9.html">论文格式</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2022/03/01/8d39085b.html">Linux部署git与Nodejs</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2021/08/27/87d44b9d.html">MIUI教程</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2021/06/01/9211474f.html">linux commd</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2021/05/05/a54293f2.html">Springboot笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2021/03/15/217f21be.html">DRL笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2021/03/01/514027fa.html">Hexo部署到阿里云OSS上</a></li><li class="post-list-item"><a class="post-list-link" href="/peaky/2021/01/28/ef00c80b.html">LayUI入门</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://space.bilibili.com/451761785" title="Bili主页" target="_blank">Bili主页</a><ul></ul><a href="https://peaky2222.github.io/peaky/" title="GitHub" target="_blank">GitHub</a><ul></ul><a href="https://hsrss.vercel.app/" title="RSSHub" target="_blank">RSSHub</a><ul></ul><a href="https://peaky2022.gitee.io/peaky/" title="Gitee" target="_blank">Gitee</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2022 <a href="/peaky/." rel="nofollow">NoteBook.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/peaky/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/peaky/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/peaky/css/search.css?v=1.0.0"><script type="text/javascript" src="/peaky/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/peaky/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/peaky/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/peaky/js/smartresize.js?v=1.0.0"></script></div></body></html>